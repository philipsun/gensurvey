root
Recent automatic text summarization techniques: a survey
1-tIntroduction
1.1-tNeed of text summarization
Text Summarization is condensing the source text into a shorter version preserving its information content and overall meaning
It is very difficult for human beings to manually summarize large documents of text
Text Summarization methods can be classified into extractive and abs tractive summarization
An extractive summarization method consists of selecting important sentences,  paragraphs etc   from the original document and concatenating them into shorter form
The importance of sentences is decided based on statistical and linguistic features of sentences
An abs tractive summarization method consists of understanding the original text and retelling it in fewer words
It uses linguistic methods to examine and interpret the text and then to find the new concepts and expressions to best describe it by generating a new shorter text that conveys the most important information from the original text document
In this paper,  a Survey of Text Summarization Extractive techniques has been presented
Multi document summarization is a fundamental tool for document understanding and has received much attention recently
2-tVarious types of text Summarization
Multi document summarization is a fundamental tool for document understanding and has received much attention recently
Given a collection of documents,  a variety of summarization methods based on different strategies have been proposed to extract the most important sentences from the original documents
However,  very few studies have been reported on aggregating different summarization methods to possibly generate better summary results
In this paper,  we propose a weighted consensus summarization method to combine the results from single summarization systems
We evaluate and compare our proposed weighted consensus method with various baseline combination methods
Experimental results on DUC2002 and DUC2004 data sets demonstrate the performance improvement by aggregating multiple summarization systems,  and our proposed weighted consensus summarization method outperforms other combination methods
Text Summarization is condensing the source text into a shorter version preserving its information content and overall meaning
It is very difficult for human beings to manually summarize large documents of text
Text Summarization methods can be classified into extractive and abs tractive summarization
An extractive summarization method consists of selecting important sentences,  paragraphs etc   from the original document and concatenating them into shorter form
The importance of sentences is decided based on statistical and linguistic features of sentences
An abs tractive summarization method consists of understanding the original text and retelling it in fewer words
It uses linguistic methods to examine and interpret the text and then to find the new concepts and expressions to best describe it by generating a new shorter text that conveys the most important information from the original text document
In this paper,  a Survey of Text Summarization Extractive techniques has been presented
The Internet provides many sources of different opinions,  expressed through user reviews of products,  blogs,  and forum discussions
Systems which could automatically summarize these opinions would be immensely useful for those who wish to use this information to make decisions
The previous work in automatic summarization has completely focused on extractive summarization,  in which key sentences are identified from the source text and extracted to form the output
An alternative solution is abs tractive summarization in which the information from the source text is first extracted into the form of abstract data which is then post processed to infer the most important message from the original text
This work is built upon past work of extractive summarization methods to create abs tractive summaries by creating new sentences in it
This paper conveys the methodology for the abs tractive summarization process and its evaluation considering Telugu,  a south Indian regional language,  as the language of study
We present an approach of identifying the most prominent text sentences using various shallow linguistic features,  taking degree of connective ness among the text units into consideration so as to minimize the poorly linked sentences in the resulting summary
As per the limitations of the current summarizing systems,  the summary generated by those systems contains poorly linked sentences and are not topically salient
Thus,  the paper aims at highlighting the effect of lexical chain scoring after the nouns and compound nouns are chained by searching for lexical cohesive relationships between words in the text using WordNet and using lexicographical relationships such as synonymy and hyponyms
In this paper,  our algorithm ranks sentences based on the sum of the scores of the words in each sentence involving approaches like term frequencies,  location of sentence in the text,  cue words and phrases,  word occurrences,  and measuring lexical similarity   measuring chain score,  word score and finally sentence score   for ranking the text units
We then identified and extracted high scored sentences and then the Vector Space approach is used to measure the relatedness similarity between the extracted sentence and the topic words involving again the WordNet lexical database relationships to prioritise the topically related sentences
A threshold angle between the two vectors is predefined experimentally to which the ranked scored sentences to be dropped and which the significant sentences with ranking scores higher than threshold to be extracted
Note that the value of threshold is predetermined based on the percentage of output summary required to be generated
Our results show that the agreement among the human subjects and our algorithm is highly significant
We find that the top ranked sentences are most of the time the most important ones that human subjects extract in our experiment
The deviation in percentage for precision and recall as obtained from human generated summary and our system generated summary is 12% and 8 % respectively
Our research work presents the concept of topic word similarity with the high ranking sentences obtained after applying various heuristics,  lexical chaining and the Vector Space approaches
Our approach for summarizing the text determines more significant and topically related sentences in the text and thus outputs a higher summary quality
We present two approaches to email thread summarization collective message summarization   CMS   applies a multi document summarization approach,  while individual message summarization   IMS   treats the problem as a sequence of single document summarization tasks
Both approaches are implemented in our general framework driven by sentence compression
Instead of a purely extractive approach,  we employ linguistic and statistical methods to generate multiple compressions,  and then select from those candidates to produce a final summary
We demonstrate these ideas on the Enron email collection – a very challenging corpus because of the highly technical language
Experimental results point to two findings that CMS represents a better approach to email thread summarization,  and that current sentence compression techniques do not improve summarization performance in this genre
This paper describes a text mining tool that performs two tasks,  namely document clustering and text summarization
These tasks have,  of course,  their corresponding counterpart in “ conventional data mining
However,  the textual,  unstructured nature of documents makes these two text mining tasks considerably more difficult than their data mining counterparts
In our system document clustering is performed by using the Autoclassdata mining algorithm
Our text summarization algorithm is based on computing the value of aTFISF   term frequency – inverse sentence frequency   measure for each word,  which is an adaptation of the conventional TFIDF   term frequency – inverse document frequency   measure of information retrieval
Sentences with high values of TFISF are selected to producea summary of the source text
The system has been evaluated on real world documents,  and the results are satisfactory
In this paper,  we consider document summarization as a multi objective optimization problem involving four objective functions,  namely information coverage,  significance,  redundancy and text coherence
These functions measure the possible summaries based on the identified core terms and main topics   i e a cluster of semantically or statistically related core terms
We choose the DUC 2005 and 2006 query oriented summarization tasks to exam the proposed model
The encouraging results indicate that the multi objective optimization based framework for document summarization is truly a promising research direction
The massive quantity of data available today in the Internet has reached such a huge volume that it has become humanly unfeasible to efficiently sieve useful information from it
3-tClassification of extractive approaches for summary generation
3.1-tStatistical based approaches
In this paper,  we consider document summarization as a multi objective optimization problem involving four objective functions,  namely information coverage,  significance,  redundancy and text coherence
These functions measure the possible summaries based on the identified core terms and main topics   i e a cluster of semantically or statistically related core terms
We choose the DUC 2005 and 2006 query oriented summarization tasks to exam the proposed model
The encouraging results indicate that the multi objective optimization based framework for document summarization is truly a promising research direction
Multi document summarization is a fundamental tool for document understanding and has received much attention recently
Given a collection of documents,  a variety of summarization methods based on different strategies have been proposed to extract the most important sentences from the original documents
However,  very few studies have been reported on aggregating different summarization methods to possibly generate better summary results
In this paper,  we propose a weighted consensus summarization method to combine the results from single summarization systems
We evaluate and compare our proposed weighted consensus method with various baseline combination methods
Experimental results on DUC2002 and DUC2004 data sets demonstrate the performance improvement by aggregating multiple summarization systems,  and our proposed weighted consensus summarization method outperforms other combination methods
Summarization based on text extraction is inherently limited,  but generation style abs tractive methods have proven challenging to build
In this work,  we propose a fully data driven approach to abs tractive sentence summarization
Our method utilizes a local attention based model that generates each word of the summary conditioned on the input sentence
While the model is structurally simple,  it can easily be trained endtoend and scales to a large amount of training data
The model shows significant performance gains on the DUC2004 shared task compared with several strong baselines
Sentence clustering plays a pivotal role in theme based summarization,  which discovers topic themes defined as the clusters of highly related sentences in order to avoid redundancy and cover more diverse information
As the length of sentences is short and the content it contains is limited,  the bagofwords cosine similarity traditionally used for document clustering is no longer reasonably suitable
Special treatment for measuring sentence similarity is necessary
In this paper,  we propose a ranking based clustering framework that utilizes ranking distribution of documents and terms to help generate high quality sentence clusters
The effectiveness of the proposed framework is demonstrated by both the cluster quality analysis and the summarization evaluation conducted on the DUC 2004 and DUC2007 data sets
We propose an abstraction based multi document summarization framework that can construct new sentences by exploring more fine grained syntactic units than sentences,  namely,  noun verb phrases
3.2-tTopic based approaches
The problem of using topic representations for multi document summarization   MDS   has received considerable attention recently
Several topic representations have been employed for producing informative and coherent summaries
In this article,  we describe five previously known topic representations and introduce two novel representations of topics based on topic themes
We present eight different methods of generating multi document summaries and evaluate each of these methods on a large set of topics used in past DUC workshops
Our evaluation results show a significant improvement in the quality of summaries based on topic themes over MDS methods that use other alternative topic representations
The problem of using topic representations for multi document summarization   MDS   has received considerable attention recently
In this paper,  we describe five different topic representations and introduce a novel representation of topics based on topic themes
3.3-tGraph based approaches
We propose a graph based method for extractivesingledocument summarization which considers importance,  non redundancy and local coherence simultaneously
We represent input documents by means of a bipartite graph consisting of sentence and entity nodes
We rank sentences on the basis of importance by applying a graph based ranking algorithm to this graph and ensure nonredundancyand local coherence of the summary by means of an optimization step
Our graph based method is applied to scienti c articles from the journal PLOSMedicine
We use human judgements to evaluate the coherence of our summaries
We compare ROUGE scores and human judgements for coherence of different systems on scienti c articles
Our method performs considerably better than other systems on this data
3.4-tDiscourse based approaches
We describe our experience in developing a discourse annotated corpus for community wide use
Working in the framework of Rhetorical Structure Theory,  we were able to create a large annotated resource with very high consistency,  using a well defined methodology and protocol
This resource is made publicly available through the Linguistic Data Consortium to enable researchers to develop empirically grounded,  discourse specific applications
With the explosion in the quantity of online text and multimedia information in recent years,  there has been a renewed interest in the automated extraction of knowledge and information in various disciplines
In this paper,  we provide a novel quantitative model for the creation of a summary by extracting a set of sentences that represent the most salient content of a text
3.5-tApproaches based on machine learning
4-t Recent automatic text summarization extractive approaches
4.1-tTrained summarizer and latent semantic analysis for summarization of text
In existing unsupervised methods,  Latent Semantic Analysis   LSA   is used for sentence selection sentences election
However,  the obtained results are less meaningful,  because singular vectors are used as the bases for sentence selection from given documents,  and singular vector components can have negative values
We propose a new unsupervised method using Nonnegative Matrix Factorization   NMF   to select sentences for automatic generic document summarization
The proposed method uses nonnegative constraints,  which are more similar to the human cognition process
As a result,  the method selects more meaningful sentences for generic document summarization than those selected using LSA
Ó 2008 Else vier Ltd
All rights reserved
Article history
Received 20 August Received in revised form 11 February Accepted 13 June Available online 8 August 2008
Multi document summarization is a fundamental tool for document understanding and has received much attention recently
Given a collection of documents,  a variety of summarization methods based on different strategies have been proposed to extract the most important sentences from the original documents
However,  very few studies have been reported on aggregating different summarization methods to possibly generate better summary results
In this paper,  we propose a weighted consensus summarization method to combine the results from single summarization systems
We evaluate and compare our proposed weighted consensus method with various baseline combination methods
4.2-tInformation extraction using sentence based abstraction technique
Sentence clustering plays a pivotal role in theme based summarization,  which discovers topic themes defined as the clusters of highly related sentences in order to avoid redundancy and cover more diverse information
As the length of sentences is short and the content it contains is limited,  the bagofwords cosine similarity traditionally used for document clustering is no longer reasonably suitable
Special treatment for measuring sentence similarity is necessary
In this paper,  we propose a ranking based clustering framework that utilizes ranking distribution of documents and terms to help generate high quality sentence clusters
The effectiveness of the proposed framework is demonstrated by both the cluster quality analysis and the summarization evaluation conducted on the DUC 2004 and DUC2007 data sets
ning,  surface realization,  etc,  and the true abs tractive summarization remains a researcher s dream   Radev et al,  2002   Joint compression and summarization has been used recently to generate high quality summaries
However,  such word based joint optimization is computationally expensive
In this Int his paper we adopt the sentence compression sentence selection pipeline approach for compressive summarization,  but propose to perform toper form summary guided compression,  rather than generic sentence based compression
To create an annotated corpus,  the human annotators were asked to compress sentences while explicitly given the important summary word sin words in the sentences
Using this corpus,  we traina supervised sentence compression model using a set of word,  syntax,  and document level features
During summarization,  we use multiple compressed sentences in the integer linear programming framework to select salient summary sentences
4.3-tText understanding and summarization through document concept lattice
This paper discusses a text extraction approach to multi document summarization that builds on single document summarization methods by using additional,  available information about the document set as a whole and the relationships between the documents
Multi document summarization differs from single in that the issues of compression,  speed,  redundancy and passage selection are critical in the formation of useful summaries
Our approach addresses these issues by using domain independent techniques based mainly on fast,  statistical processing,  a metric for reducing redundancy and maximizing diversity in the selected passages,  and a modular framework to allow easy parameterization for different genres,  corpora characteristics and user requirements
Text Summarization is condensing the source text into a shorter version preserving its information content and overall meaning
It is very difficult for human beings to manually summarize large documents of text
Text Summarization methods can be classified into extractive and abs tractive summarization
An extractive summarization method consists of selecting important sentences,  paragraphs etc   from the original document and concatenating them into shorter form
The importance of sentences is decided based on statistical and linguistic features of sentences
An abs tractive summarization method consists of understanding the original text and retelling it in fewer words
4.4-tSentence extraction through contextual information and statistical based summarization of text
Text Summarization is condensing the source text into a shorter version preserving its information content and overall meaning
It is very difficult for human beings to manually summarize large documents of text
Text Summarization methods can be classified into extractive and abs tractive summarization
An extractive summarization method consists of selecting important sentences,  paragraphs etc   from the original document and concatenating them into shorter form
The importance of sentences is decided based on statistical and linguistic features of sentences
An abs tractive summarization method consists of understanding the original text and retelling it in fewer words
It uses linguistic methods to examine and interpret the text and then to find the new concepts and expressions to best describe it by generating a new shorter text that conveys the most important information from the original text document
In this paper,  a Survey of Text Summarization Extractive techniques has been presented
ning,  surface realization,  etc,  and the true abs tractive summarization remains a researcher s dream   Radev et al,  2002   Joint compression and summarization has been used recently to generate high quality summaries
However,  such word based joint optimization is computationally expensive
In this Int his paper we adopt the sentence compression sentence selection pipeline approach for compressive summarization,  but propose to perform toper form summary guided compression,  rather than generic sentence based compression
To create an annotated corpus,  the human annotators were asked to compress sentences while explicitly given the important summary word sin words in the sentences
4.5-tSummarization of emails through conversational cohesion and subjective opinions
In this paper,  we study the problem of summarizing email conversations
We first build a sentence quotation graph that captures the conversation structure among emails
We adopt three cohesion measures clue words,  semantic similarity and cosine similarity as the weight of the edges
Second,  we use two graph based summarization approaches,  Generalized ClueWordSummarizer and PageRank,  to extract sentences as summaries
Third,  we propose a summarization approach based on subjective opinions and integrate it with the graph based ones
The empirical evaluation shows that the basic clue words have the highest accuracy among the three cohesion measures
Moreover,  subjective words can significantly improve accuracy
We present two approaches to email thread summarization collective message summarization   CMS   applies a multi document summarization approach,  while individual message summarization   IMS   treats the problem as a sequence of single document summarization tasks
Both approaches are implemented in our general framework driven by sentence compression
Instead of a purely extractive approach,  we employ linguistic and statistical methods to generate multiple compressions,  and then select from those candidates to produce a final summary
We demonstrate these ideas on the Enron email collection – a very challenging corpus because of the highly technical language
Experimental results point to two findings that CMS represents a better approach to email thread summarization,  and that current sentence compression techniques do not improve summarization performance in this genre
Multi document summarization is a fundamental tool for document understanding and has received much attention recently
Given a collection of documents,  a variety of summarization methods based on different strategies have been proposed to extract the most important sentences from the original documents
However,  very few studies have been reported on aggregating different summarization methods to possibly generate better summary results
In this paper,  we propose a weighted consensus summarization method to combine the results from single summarization systems
4.6-tSummarization of text through complex network approach
Text Summarization is condensing the source text into a shorter version preserving its information content and overall meaning
It is very difficult for human beings to manually summarize large documents of text
Text Summarization methods can be classified into extractive and abs tractive summarization
An extractive summarization method consists of selecting important sentences,  paragraphs etc   from the original document and concatenating them into shorter form
The importance of sentences is decided based on statistical and linguistic features of sentences
An abs tractive summarization method consists of understanding the original text and retelling it in fewer words
It uses linguistic methods to examine and interpret the text and then to find the new concepts and expressions to best describe it by generating a new shorter text that conveys the most important information from the original text document
In this paper,  a Survey of Text Summarization Extractive techniques has been presented
We present two approaches to email thread summarization collective message summarization   CMS   applies a multi document summarization approach,  while individual message summarization   IMS   treats the problem as a sequence of single document summarization tasks
Both approaches are implemented in our general framework driven by sentence compression
Instead of a purely extractive approach,  we employ linguistic and statistical methods to generate multiple compressions,  and then select from those candidates to produce a final summary
We demonstrate these ideas on the Enron email collection – a very challenging corpus because of the highly technical language
Experimental results point to two findings that CMS represents a better approach to email thread summarization,  and that current sentence compression techniques do not improve summarization performance in this genre
4.7-tAutomatic creation of generic document summaries through non-negative matrix factorization
In existing unsupervised methods,  Latent Semantic Analysis   LSA   is used for sentence selection sentences election
However,  the obtained results are less meaningful,  because singular vectors are used as the bases for sentence selection from given documents,  and singular vector components can have negative values
We propose a new unsupervised method using Nonnegative Matrix Factorization   NMF   to select sentences for automatic generic document summarization
The proposed method uses nonnegative constraints,  which are more similar to the human cognition process
As a result,  the method selects more meaningful sentences for generic document summarization than those selected using LSA
Ó 2008 Else vier Ltd
All rights reserved
Article history
Received 20 August Received in revised form 11 February Accepted 13 June Available online 8 August 2008
This paper discusses a text extraction approach to multi document summarization that builds on single document summarization methods by using additional,  available information about the document set as a whole and the relationships between the documents
Multi document summarization differs from single in that the issues of compression,  speed,  redundancy and passage selection are critical in the formation of useful summaries
Our approach addresses these issues by using domain independent techniques based mainly on fast,  statistical processing,  a metric for reducing redundancy and maximizing diversity in the selected passages,  and a modular framework to allow easy parameterization for different genres,  corpora characteristics and user requirements
Probabilistic Latent Semantic Analysis   PLSA   has been popularly used in document analysis
However,  as it is currently formulated,  PLSA strictly requires the number of word latent classes to be equal to the number of document latent classes
4.8-tAutomatic text summarization using MR, GA, FFNN, GMM and PNN based models
This work proposes an approach to address the problem of improving content selection in automatic text summarization by using some statistical tools
This approach is a trainable summarizer,  which takes into account several features,  including sentence position,  positive keyword,  negative keyword,  sentence centrality,  sentence resemblance to the title,  sentence inclusion of name entity,  sentence inclusion of numerical data,  sentence relative length,  Bushy path of the sentence and aggregated similarity for each sentence to generate summaries
First,  we investigate the effect of each sentence feature on the summarization task
Then we use all features in combination to train genetic algorithm   GA   and mathematical regression   MR   models to obtain a suitable combination of feature weights
Moreover,  we use all feature parameters to train feed forward neural network   FFNN  ,  probabilistic neural network   PNN   and Gaussian mixture model   GMM   in order to construct a text summarizer for each model
Furthermore,  we use trained models by one language to test summarization performance in the other language
The proposed approach performance is measured at several compression rates on a data corpus composed of 100 Arabic political articles and 100 English religious articles
The results of the proposed approach are promising,  especially the GMM approach
Text Summarization is condensing the source text into a shorter version preserving its information content and overall meaning
It is very difficult for human beings to manually summarize large documents of text
Text Summarization methods can be classified into extractive and abs tractive summarization
An extractive summarization method consists of selecting important sentences,  paragraphs etc   from the original document and concatenating them into shorter form
The importance of sentences is decided based on statistical and linguistic features of sentences
An abs tractive summarization method consists of understanding the original text and retelling it in fewer words
It uses linguistic methods to examine and interpret the text and then to find the new concepts and expressions to best describe it by generating a new shorter text that conveys the most important information from the original text document
4.9-tQuery-based summarization of multiple documents by applying regression models
We develop a Ranking framework upon Recursive Neural Networks   R2N2   to rank sentences for multi document summarization
It formulates the sentence ranking task as a hierarchical regression process,  which simultaneously measures the salience of a sentence and its constituents   e g,  phrases   in the parsing tree
This enables us to draw on word level to sentence level supervisions derived from reference summaries
In addition,  recursive neural networks are used to automatically learn ranking features over the tree,  with handcrafted feature vectors of words as inputs
Hierarchical regressions are then conducted with learned features concatenating raw features
Ranking scores of sentences and words are utilized to effectively select informative and non redundant sentences to generate summaries
Experiments on the DUC 2001,  2002 and 2004 multi document summarization data sets show that R2N2 outperforms stateoftheart extractive summarization approaches
Multi document summarization is a fundamental tool for document understanding and has received much attention recently
Given a collection of documents,  a variety of summarization methods based on different strategies have been proposed to extract the most important sentences from the original documents
However,  very few studies have been reported on aggregating different summarization methods to possibly generate better summary results
In this paper,  we propose a weighted consensus summarization method to combine the results from single summarization systems
4.10-tMaximum coverage and minimum redundancy in summarization of text
Text Summarization is condensing the source text into a shorter version preserving its information content and overall meaning
It is very difficult for human beings to manually summarize large documents of text
Text Summarization methods can be classified into extractive and abs tractive summarization
An extractive summarization method consists of selecting important sentences,  paragraphs etc   from the original document and concatenating them into shorter form
The importance of sentences is decided based on statistical and linguistic features of sentences
An abs tractive summarization method consists of understanding the original text and retelling it in fewer words
It uses linguistic methods to examine and interpret the text and then to find the new concepts and expressions to best describe it by generating a new shorter text that conveys the most important information from the original text document
In this paper,  a Survey of Text Summarization Extractive techniques has been presented
In this paper,  we consider document summarization as a multi objective optimization problem involving four objective functions,  namely information coverage,  significance,  redundancy and text coherence
These functions measure the possible summaries based on the identified core terms and main topics   i e a cluster of semantically or statistically related core terms
We choose the DUC 2005 and 2006 query oriented summarization tasks to exam the proposed model
The encouraging results indicate that the multi objective optimization based framework for document summarization is truly a promising research direction
The massive quantity of data available today in the Internet has reached such a huge volume that it has become humanly unfeasible to efficiently sieve useful information from it
One solution to this problem is offered by using text summarization techniques
Text summarization,  the process of automatically creating a shorter version of one or more text documents,  is an important way of finding relevant information in large text libraries or in the Internet
This paper presents a multi document summarization system that concisely extracts the main aspects of a set of documents,  trying to avoid the typical problems of this type of summarization information redundancy and diversity
4.11-tSummarization of documents through a progressive technique for selection of sentences
4.12-tEvaluation of sentence scoring methods for extractive summarization of text
Text Summarization is condensing the source text into a shorter version preserving its information content and overall meaning
It is very difficult for human beings to manually summarize large documents of text
Text Summarization methods can be classified into extractive and abs tractive summarization
An extractive summarization method consists of selecting important sentences,  paragraphs etc   from the original document and concatenating them into shorter form
The importance of sentences is decided based on statistical and linguistic features of sentences
An abs tractive summarization method consists of understanding the original text and retelling it in fewer words
It uses linguistic methods to examine and interpret the text and then to find the new concepts and expressions to best describe it by generating a new shorter text that conveys the most important information from the original text document
In this paper,  a Survey of Text Summarization Extractive techniques has been presented
Multi document summarization is a fundamental tool for document understanding and has received much attention recently
Given a collection of documents,  a variety of summarization methods based on different strategies have been proposed to extract the most important sentences from the original documents
However,  very few studies have been reported on aggregating different summarization methods to possibly generate better summary results
In this paper,  we propose a weighted consensus summarization method to combine the results from single summarization systems
We evaluate and compare our proposed weighted consensus method with various baseline combination methods
Experimental results on DUC2002 and DUC2004 data sets demonstrate the performance improvement by aggregating multiple summarization systems,  and our proposed weighted consensus summarization method outperforms other combination methods
ning,  surface realization,  etc,  and the true abs tractive summarization remains a researcher s dream   Radev et al,  2002   Joint compression and summarization has been used recently to generate high quality summaries
4.13-tExploring correlations among multiple terms through a graph-based summarizer, GRAPHSUM
Graph based summarization entails extracting a worthwhile subset of sentences from a collection of textual documents by using a graph based model to represent the correlations between pairs of document terms
However,  since the high order correlations among multiple terms are disregarded during graph evaluation,  the summarization performance could be limited unless integrating ad hoc language dependent or semantics based analysis
This paper presents a novel and general purpose graph based summarizer,  namely GraphSum   Graph based Summarizer
It discovers and exploits association rules to represent the correlations among multiple terms that have been neglected by previous approaches
The graph nodes,  which represent combinations of two or more terms,  are first ranked by means of a PageRank strategy that discriminates between positive and negative term correlations
Then,  the produced node ranking is used to drive the sentence selection process
The experiments performed on benchmark and real life documents demonstrate the effectiveness of the proposed approach compared to many stateoftheart summarizers
one or more model   reference   summaries
The method is similar in nature to Basic Elements   Hovy et al,  2005  ,  in that it extends beyonda simple string comparison of word sequences,  reaching instead to a deeper linguistic analysis of the text
Using a re ranking reran king parser and a LexicalFunctional Grammar   LFG   annotation,  we produce as et of dependency triples for each summary
The dependency set for each candidate summary is then automatically compared against dependencies generated from model summaries
We examine an umber of variations of the method,  including the addition of WordNet,  partial matching,  or removing relation labels from the dependencies
4.14-tIncorporating various levels of language analysis for tackling redundancy in text summarization
4.15-tEvolutionary optimization algorithm for summarizing multiple documents
In this paper,  we consider document summarization as a multi objective optimization problem involving four objective functions,  namely information coverage,  significance,  redundancy and text coherence
These functions measure the possible summaries based on the identified core terms and main topics   i e a cluster of semantically or statistically related core terms
We choose the DUC 2005 and 2006 query oriented summarization tasks to exam the proposed model
The encouraging results indicate that the multi objective optimization based framework for document summarization is truly a promising research direction
We treat the text summarization problem as maximizing a sub modular function under abudget constraint
We show,  both theoretically and empirically,  a modified greedy algorithm can efficiently solve the budgeted sub modular maximization problem near optimally,  and we derive new approximation bounds in doing so
Experiments on DUC’04 task show that our approach is superior to the best performing method from the DUC’04 evaluation on ROUGE1 scores
Multi document summarization techniques aim to reduce documents into a small set of words or paragraphs that convey the main meaning of the original document
Many approaches to multi document summarization have used probability based methods and machine learning techniques to simultaneously summarize multiple documents sharing a common topic
4.16-tSummarization of multiple documents using a hybrid machine learning model
4.17-tImproving clustering at sentence-level with the help of ranking-based technique for theme-based summarization
Sentence clustering plays a pivotal role in theme based summarization,  which discovers topic themes defined as the clusters of highly related sentences in order to avoid redundancy and cover more diverse information
As the length of sentences is short and the content it contains is limited,  the bagofwords cosine similarity traditionally used for document clustering is no longer reasonably suitable
Special treatment for measuring sentence similarity is necessary
In this paper,  we propose a ranking based clustering framework that utilizes ranking distribution of documents and terms to help generate high quality sentence clusters
The effectiveness of the proposed framework is demonstrated by both the cluster quality analysis and the summarization evaluation conducted on the DUC 2004 and DUC2007 data sets
Multi document summarization is a fundamental tool for document understanding and has received much attention recently
Given a collection of documents,  a variety of summarization methods based on different strategies have been proposed to extract the most important sentences from the original documents
However,  very few studies have been reported on aggregating different summarization methods to possibly generate better summary results
In this paper,  we propose a weighted consensus summarization method to combine the results from single summarization systems
We evaluate and compare our proposed weighted consensus method with various baseline combination methods
Experimental results on DUC2002 and DUC2004 data sets demonstrate the performance improvement by aggregating multiple summarization systems,  and our proposed weighted consensus summarization method outperforms other combination methods
The technology of automatic document summarization is maturing and may provide a solution to the information overload problem
Nowadays,  document summarization plays an important role in information retrieval
4.18-tStatistical and linguistic based summarization system for multiple documents
Multi document summarization is a fundamental tool for document understanding and has received much attention recently
Given a collection of documents,  a variety of summarization methods based on different strategies have been proposed to extract the most important sentences from the original documents
However,  very few studies have been reported on aggregating different summarization methods to possibly generate better summary results
In this paper,  we propose a weighted consensus summarization method to combine the results from single summarization systems
We evaluate and compare our proposed weighted consensus method with various baseline combination methods
Experimental results on DUC2002 and DUC2004 data sets demonstrate the performance improvement by aggregating multiple summarization systems,  and our proposed weighted consensus summarization method outperforms other combination methods
This paper discusses a text extraction approach to multi document summarization that builds on single document summarization methods by using additional,  available information about the document set as a whole and the relationships between the documents
Multi document summarization differs from single in that the issues of compression,  speed,  redundancy and passage selection are critical in the formation of useful summaries
Our approach addresses these issues by using domain independent techniques based mainly on fast,  statistical processing,  a metric for reducing redundancy and maximizing diversity in the selected passages,  and a modular framework to allow easy parameterization for different genres,  corpora characteristics and user requirements
The massive quantity of data available today in the Internet has reached such a huge volume that it has become humanly unfeasible to efficiently sieve useful information from it
4.19-tMulti-document summarization based information retrieval using event graphs
4.20-textractive summarization of single documents through genetic operators and guided local search
4.21-t Topic-aspect based summarization through selection of groups
Multi document summarization is a fundamental tool for document understanding and has received much attention recently
Given a collection of documents,  a variety of summarization methods based on different strategies have been proposed to extract the most important sentences from the original documents
However,  very few studies have been reported on aggregating different summarization methods to possibly generate better summary results
In this paper,  we propose a weighted consensus summarization method to combine the results from single summarization systems
We evaluate and compare our proposed weighted consensus method with various baseline combination methods
Experimental results on DUC2002 and DUC2004 data sets demonstrate the performance improvement by aggregating multiple summarization systems,  and our proposed weighted consensus summarization method outperforms other combination methods
ning,  surface realization,  etc,  and the true abs tractive summarization remains a researcher s dream   Radev et al,  2002   Joint compression and summarization has been used recently to generate high quality summaries
However,  such word based joint optimization is computationally expensive
In this Int his paper we adopt the sentence compression sentence selection pipeline approach for compressive summarization,  but propose to perform toper form summary guided compression,  rather than generic sentence based compression
To create an annotated corpus,  the human annotators were asked to compress sentences while explicitly given the important summary word sin words in the sentences
Using this corpus,  we traina supervised sentence compression model using a set of word,  syntax,  and document level features
During summarization,  we use multiple compressed sentences in the integer linear programming framework to select salient summary sentences
4.22-tSummarization of multiple documents based on social Folksonomy by analyzing semantically
Multi document summarization techniques aim to reduce documents into a small set of words or paragraphs that convey the main meaning of the original document
Many approaches to multi document summarization have used probability based methods and machine learning techniques to simultaneously summarize multiple documents sharing a common topic
However,  these techniques fail to semantically analyze proper nouns and newly coined words because most depend on an outofdate dictionary or thesaurus
To overcome these drawbacks,  we propose a novel multi document summarization system called FoDoSu,  or Folksonomybased MultiDocument Summarization,  that employs the tag clusters used by Flickr,  a Folksonomy system,  for detecting key sentences from multiple documents
We first create a word frequency table for analyzing the semantics and contributions of words using the HITS algorithm
Then,  by exploiting tag clusters,  we analyze the semantic relationships between words in the word frequency table
Finally,  we create a summary of multiple documents by analyzing the importance of each word and its semantic relatedness to others
Experimental results from the TAC 2008 and 2009 data sets demonstrate the improvement of our proposed framework over existing summarization systems
Multi document summarization is a fundamental tool for document understanding and has received much attention recently
Given a collection of documents,  a variety of summarization methods based on different strategies have been proposed to extract the most important sentences from the original documents
However,  very few studies have been reported on aggregating different summarization methods to possibly generate better summary results
4.23-tOther text summarization approaches
4.23.1-tLearning-based approach for summarizing related sentences
4.23.2-tSemantic role labeling with minimal resources
We propose a framework for abs tractive summarization of multi documents,  which aims to select contents of summary not from the source document sentences but from the semantic representation of the source documents
In this framework,  contents of the source documents are represented by predicate argument structures by employing semantic role labeling
Content selection for summary is made by ranking the predicate argument structures based on optimized features,  and using language generation for generating sentences from predicate argument structures
Our proposed framework differs from other abs tractive summarization approaches in a few aspects
First,  it employs semantic role labeling for semantic representation of text
Secondly,  it analyzes the source text semantically by utilizing semantic similarity measure in order to cluster semantically similar predicate argument structures across the text and finally it ranks the predicate argument structures based on features weighted by genetic algorithm   GA
4.23.3-tSummarizing single documents through nested tree structure
4.23.4-tTwo-level sparse representation model for summarization of multiple documents
Multi document summarization is of great value to many tom any real world applications since it can help people get the main ideas within a short time
In this paper,  we tackle the problem of extracting summary sentences from multi document sets by applying sparse coding techniques and present a novel framework to this challenging problem
Based on the data reconstruction and sentence de noising assumption,  we present a twolevelsparse representation model to depict the process ofmultidocument summarization
Three requisite properties is proposed to form an ideal re constructable reconstruct able sum
mary
Coverage,  Sparsity and Diversity
We then for
malize the task of multi document summarization as an optimization problem according to the above properties,  and use simulated annealing algorithm to solve it
4.23.5-tSparse-coding based reader-aware summarization system for multiple documents
Multi document summarization is a fundamental tool for document understanding and has received much attention recently
Given a collection of documents,  a variety of summarization methods based on different strategies have been proposed to extract the most important sentences from the original documents
However,  very few studies have been reported on aggregating different summarization methods to possibly generate better summary results
In this paper,  we propose a weighted consensus summarization method to combine the results from single summarization systems
We evaluate and compare our proposed weighted consensus method with various baseline combination methods
4.23.6-tSummarization of multiple documents through recursive neural networks based ranking approach
We develop a Ranking framework upon Recursive Neural Networks   R2N2   to rank sentences for multi document summarization
It formulates the sentence ranking task as a hierarchical regression process,  which simultaneously measures the salience of a sentence and its constituents   e g,  phrases   in the parsing tree
This enables us to draw on word level to sentence level supervisions derived from reference summaries
In addition,  recursive neural networks are used to automatically learn ranking features over the tree,  with handcrafted feature vectors of words as inputs
Hierarchical regressions are then conducted with learned features concatenating raw features
Ranking scores of sentences and words are utilized to effectively select informative and non redundant sentences to generate summaries
4.23.7-tGraph-based extractive summarization by considering importance, non-redundancy and coherence
We propose a graph based method for extractivesingledocument summarization which considers importance,  non redundancy and local coherence simultaneously
We represent input documents by means of a bipartite graph consisting of sentence and entity nodes
We rank sentences on the basis of importance by applying a graph based ranking algorithm to this graph and ensure nonredundancyand local coherence of the summary by means of an optimization step
Our graph based method is applied to scienti c articles from the journal PLOSMedicine
We use human judgements to evaluate the coherence of our summaries
4.23.8-tSparse optimization based compressive document summarization
4.23.9-t Submodular mixtures based summarization of multi-document hierarchy of topics
We study the problem of summarizing DAGstructured topic hierarchies over a given set of documents
Example applications include automatically generating Wikipedia disambiguation pages for a set of articles,  and generating candidate multi labels for preparing machine learning data sets   e g,  for text classification,  functional genomics,  and image classification
Unlike previous work,  which focuses on clustering the set of documents using the topic hierarchy as features,  we directly pose the problem as a sub modular optimization problem on a topic hierarchy using the documents as features
Desirable properties of the chosen topics include document coverage,  specificity,  topic diversity,  and topic homogeneity,  each of which,  we show,  is naturally modeled by a sub modular function
4.23.10-tDisaster summarization through prediction of salient updates
During crises such as natural disasters or other human tragedies,  information needs of both civilians and responders often require urgent,  specialized treatment
Monitoring and summarizing a text stream during such an event remains a difficult problem
We present a system for update summarization which predicts the salience of sentences with respect to an event and then uses these predictions to directly bias a clustering algorithm for sentence selection,  increasing the quality of the updates
We use novel,  disaster specific features for salience prediction,  including geolocations and language models representing the language of disaster
4.23.11-tSummarizing multiple documents through system combination
This paper discusses a text extraction approach to multi document summarization that builds on single document summarization methods by using additional,  available information about the document set as a whole and the relationships between the documents
Multi document summarization differs from single in that the issues of compression,  speed,  redundancy and passage selection are critical in the formation of useful summaries
Our approach addresses these issues by using domain independent techniques based mainly on fast,  statistical processing,  a metric for reducing redundancy and maximizing diversity in the selected passages,  and a modular framework to allow easy parameterization for different genres,  corpora characteristics and user requirements
4.23.12-tPhrase-based compressive cross-language summarization
4.23.13-t Re-evaluation of automatic summarization using BLEU and 192 variants of ROUGE
We provide an analysis of current evaluation methodologies applied to summarization metrics and identify the following areas of concern
1   movement away from evaluation by correlation with human assessment   2   omission of important components of human assessment from evaluations,  in addition to large numbers of metric variants   3   absence of methods of significance testing improvements over a baseline
We outline an evaluation methodology that overcomes all such challenges,  providing the first method of significance testing suitable for evaluation of summarization metrics
Our evaluation reveals for the first time which metric variants significantly outperform others,  optimal metric variants distinct from current recommended best variants,  as well as machine translation metric BLEU to have performance on par with ROUGE for the purpose of evaluation of summarization systems
4.24-tPro and Cons
5-tComparison of recent automatic text summarization extractive approaches
6-tAbstractive approaches for text summarization
Text Summarization is condensing the source text into a shorter version preserving its information content and overall meaning
It is very difficult for human beings to manually summarize large documents of text
Text Summarization methods can be classified into extractive and abs tractive summarization
An extractive summarization method consists of selecting important sentences,  paragraphs etc   from the original document and concatenating them into shorter form
The importance of sentences is decided based on statistical and linguistic features of sentences
An abs tractive summarization method consists of understanding the original text and retelling it in fewer words
It uses linguistic methods to examine and interpret the text and then to find the new concepts and expressions to best describe it by generating a new shorter text that conveys the most important information from the original text document
In this paper,  a Survey of Text Summarization Extractive techniques has been presented
The Internet provides many sources of different opinions,  expressed through user reviews of products,  blogs,  and forum discussions
Systems which could automatically summarize these opinions would be immensely useful for those who wish to use this information to make decisions
The previous work in automatic summarization has completely focused on extractive summarization,  in which key sentences are identified from the source text and extracted to form the output
An alternative solution is abs tractive summarization in which the information from the source text is first extracted into the form of abstract data which is then post processed to infer the most important message from the original text
This work is built upon past work of extractive summarization methods to create abs tractive summaries by creating new sentences in it
This paper conveys the methodology for the abs tractive summarization process and its evaluation considering Telugu,  a south Indian regional language,  as the language of study
Multi document summarization is a fundamental tool for document understanding and has received much attention recently
Given a collection of documents,  a variety of summarization methods based on different strategies have been proposed to extract the most important sentences from the original documents
However,  very few studies have been reported on aggregating different summarization methods to possibly generate better summary results
In this paper,  we propose a weighted consensus summarization method to combine the results from single summarization systems
We evaluate and compare our proposed weighted consensus method with various baseline combination methods
Experimental results on DUC2002 and DUC2004 data sets demonstrate the performance improvement by aggregating multiple summarization systems,  and our proposed weighted consensus summarization method outperforms other combination methods
We present two approaches to email thread summarization collective message summarization   CMS   applies a multi document summarization approach,  while individual message summarization   IMS   treats the problem as a sequence of single document summarization tasks
Both approaches are implemented in our general framework driven by sentence compression
Instead of a purely extractive approach,  we employ linguistic and statistical methods to generate multiple compressions,  and then select from those candidates to produce a final summary
We demonstrate these ideas on the Enron email collection – a very challenging corpus because of the highly technical language
Experimental results point to two findings that CMS represents a better approach to email thread summarization,  and that current sentence compression techniques do not improve summarization performance in this genre
We present an approach of identifying the most prominent text sentences using various shallow linguistic features,  taking degree of connective ness among the text units into consideration so as to minimize the poorly linked sentences in the resulting summary
As per the limitations of the current summarizing systems,  the summary generated by those systems contains poorly linked sentences and are not topically salient
Thus,  the paper aims at highlighting the effect of lexical chain scoring after the nouns and compound nouns are chained by searching for lexical cohesive relationships between words in the text using WordNet and using lexicographical relationships such as synonymy and hyponyms
In this paper,  our algorithm ranks sentences based on the sum of the scores of the words in each sentence involving approaches like term frequencies,  location of sentence in the text,  cue words and phrases,  word occurrences,  and measuring lexical similarity   measuring chain score,  word score and finally sentence score   for ranking the text units
We then identified and extracted high scored sentences and then the Vector Space approach is used to measure the relatedness similarity between the extracted sentence and the topic words involving again the WordNet lexical database relationships to prioritise the topically related sentences
A threshold angle between the two vectors is predefined experimentally to which the ranked scored sentences to be dropped and which the significant sentences with ranking scores higher than threshold to be extracted
Note that the value of threshold is predetermined based on the percentage of output summary required to be generated
Our results show that the agreement among the human subjects and our algorithm is highly significant
We find that the top ranked sentences are most of the time the most important ones that human subjects extract in our experiment
The deviation in percentage for precision and recall as obtained from human generated summary and our system generated summary is 12% and 8 % respectively
Our research work presents the concept of topic word similarity with the high ranking sentences obtained after applying various heuristics,  lexical chaining and the Vector Space approaches
Our approach for summarizing the text determines more significant and topically related sentences in the text and thus outputs a higher summary quality
This paper proposes two approaches to address text summarization modified corpus based approach   MCBA   and LSAbased T
R.M approach   LSA + T
When the compression rate was 30%,  an average fmeasure of 49% for MCBA,  52% for MCBA + GA,  44% and 40% for LSA + T
R.M in single document and corpus level were achieved respectively
R.M
The first is a trainable summarizer,  which takes into account several features,  including position,  positive keyword,  negative keyword,  centrality,  and the resemblance to the title,  to generate summaries
Two new ideas are exploited
1   sentence positions are ranked to emphasize the significances of different sentence positions,  and   2   the score function is trained by the genetic algorithm   GA   to obtain a suitable combination of feature weights
The second uses latent semantic analysis   LSA   to derive the semantic matrix of a document or a corpus and uses semantic sentence representation to construct a semantic text relationship map
We evaluate LSA + T
R.M both with single documents and at the corpus level to investigate the competence of LSA in text summarization
The two novel approaches were measured at several compression rates on a data corpus composed of 100 political articles
This paper describes a text mining tool that performs two tasks,  namely document clustering and text summarization
These tasks have,  of course,  their corresponding counterpart in “ conventional data mining
However,  the textual,  unstructured nature of documents makes these two text mining tasks considerably more difficult than their data mining counterparts
In our system document clustering is performed by using the Autoclassdata mining algorithm
Our text summarization algorithm is based on computing the value of aTFISF   term frequency – inverse sentence frequency   measure for each word,  which is an adaptation of the conventional TFIDF   term frequency – inverse document frequency   measure of information retrieval
Sentences with high values of TFISF are selected to producea summary of the source text
The system has been evaluated on real world documents,  and the results are satisfactory
In this paper,  we consider document summarization as a multi objective optimization problem involving four objective functions,  namely information coverage,  significance,  redundancy and text coherence
These functions measure the possible summaries based on the identified core terms and main topics   i e a cluster of semantically or statistically related core terms
7-tMultilingual approaches for text summarization
In this paper we present NewsGist,  a multilingual,  multi document news summarization system underpinned by the Singular Value Decomposition   SVD   paradigm for document summarization and purpose built for the Europe Media Monitor   EMM
The summarization method employed yielded stateoftheart performance for English at the Update Summarization task of the last Text Analysis Conference   TAC   2009 and integrated with EMM represents the first online summarization system able to produce summaries for so many languages
We discuss the context and motivation for developing the system and provide an overview of its architecture
The paper is intended to serve as accompaniment of a live demo of the system,  which can be of interest to researchers and engineers working on multilingual open source news analysis and mining
This paper concentrates on hybrid algorithm for multilingual summarization of Hindi and Punjabi documents
It combines the features of Hindi summarizer as suggested by CDAC Noida and Punjabi summarizer as suggested by Gupta and Lehal in 2012
This algorithm performs well at 30% compression ratio for both intrinsic and extrinsic measures of summary evaluation
This algorithm has been thoroughly tested on 30 HindiPunjabi documents and reports FScore equal to 92
56% which is reasonably good
In addition to this,  it also suggests some new features for summarizing Hindi and Punjabi multilingual text
It is first time that this multilingual text summarizer has been proposed which supports both Hindi and Punjabi text
Nine features used in this algorithm for summarizing multilingual Hindi and Punjabi text are
1   Key phrase extraction 2   Font feature 3   Nouns and Verbs Extraction 4   Position feature 5   Cue phrase feature 6   Negative keywords extraction 7   Named Entities extraction 8   Relative length feature 9   extraction of number data
For each sentence,  scores of each feature is calculated and then machine learning based mathematical regression is applied for identifying weights of these nine features
Sentence final scores finals cores are calculated from feature weight equations
Top scored sentences in proper order   in same order as in input   are selected for final summary
Default summary is made at 30% compression ratio
Text Summarization is condensing the source text into a shorter version preserving its information content and overall meaning
It is very difficult for human beings to manually summarize large documents of text
Text Summarization methods can be classified into extractive and abs tractive summarization
An extractive summarization method consists of selecting important sentences,  paragraphs etc   from the original document and concatenating them into shorter form
The importance of sentences is decided based on statistical and linguistic features of sentences
An abs tractive summarization method consists of understanding the original text and retelling it in fewer words
It uses linguistic methods to examine and interpret the text and then to find the new concepts and expressions to best describe it by generating a new shorter text that conveys the most important information from the original text document
In this paper,  a Survey of Text Summarization Extractive techniques has been presented
The Internet provides many sources of different opinions,  expressed through user reviews of products,  blogs,  and forum discussions
Systems which could automatically summarize these opinions would be immensely useful for those who wish to use this information to make decisions
The previous work in automatic summarization has completely focused on extractive summarization,  in which key sentences are identified from the source text and extracted to form the output
An alternative solution is abs tractive summarization in which the information from the source text is first extracted into the form of abstract data which is then post processed to infer the most important message from the original text
This work is built upon past work of extractive summarization methods to create abs tractive summaries by creating new sentences in it
This paper conveys the methodology for the abs tractive summarization process and its evaluation considering Telugu,  a south Indian regional language,  as the language of study
Multi document summarization is a fundamental tool for document understanding and has received much attention recently
Given a collection of documents,  a variety of summarization methods based on different strategies have been proposed to extract the most important sentences from the original documents
However,  very few studies have been reported on aggregating different summarization methods to possibly generate better summary results
In this paper,  we propose a weighted consensus summarization method to combine the results from single summarization systems
We evaluate and compare our proposed weighted consensus method with various baseline combination methods
Experimental results on DUC2002 and DUC2004 data sets demonstrate the performance improvement by aggregating multiple summarization systems,  and our proposed weighted consensus summarization method outperforms other combination methods
We present two approaches to email thread summarization collective message summarization   CMS   applies a multi document summarization approach,  while individual message summarization   IMS   treats the problem as a sequence of single document summarization tasks
Both approaches are implemented in our general framework driven by sentence compression
Instead of a purely extractive approach,  we employ linguistic and statistical methods to generate multiple compressions,  and then select from those candidates to produce a final summary
We demonstrate these ideas on the Enron email collection – a very challenging corpus because of the highly technical language
Experimental results point to two findings that CMS represents a better approach to email thread summarization,  and that current sentence compression techniques do not improve summarization performance in this genre
We present an approach of identifying the most prominent text sentences using various shallow linguistic features,  taking degree of connective ness among the text units into consideration so as to minimize the poorly linked sentences in the resulting summary
As per the limitations of the current summarizing systems,  the summary generated by those systems contains poorly linked sentences and are not topically salient
Thus,  the paper aims at highlighting the effect of lexical chain scoring after the nouns and compound nouns are chained by searching for lexical cohesive relationships between words in the text using WordNet and using lexicographical relationships such as synonymy and hyponyms
In this paper,  our algorithm ranks sentences based on the sum of the scores of the words in each sentence involving approaches like term frequencies,  location of sentence in the text,  cue words and phrases,  word occurrences,  and measuring lexical similarity   measuring chain score,  word score and finally sentence score   for ranking the text units
8-tSummary evaluation
8.1-tInformativeness evaluation
We provide an analysis of current evaluation methodologies applied to summarization metrics and identify the following areas of concern
1   movement away from evaluation by correlation with human assessment   2   omission of important components of human assessment from evaluations,  in addition to large numbers of metric variants   3   absence of methods of significance testing improvements over a baseline
We outline an evaluation methodology that overcomes all such challenges,  providing the first method of significance testing suitable for evaluation of summarization metrics
Our evaluation reveals for the first time which metric variants significantly outperform others,  optimal metric variants distinct from current recommended best variants,  as well as machine translation metric BLEU to have performance on par with ROUGE for the purpose of evaluation of summarization systems
We subsequently replicate a recent large scale evaluation that relied on,  what we now know to be,  suboptimal ROUGE variants revealing distinct conclusions about the relative performance of stateoftheart summarization systems
As part of evaluating a summary automatically,  it is usual to determine how much of the contents of one or more human produced ideal summaries it contains
Past automated methods such as ROUGE compare using fixed word ngrams,  which are not ideal for a variety of reasons
In this paper we describe a framework in which summary evaluation measures can be instantiated and compared,  and we implement a specific evaluation method using very small units of content,  called Basic Elements,  that address some of the shortcomings of ngrams
This method is tested on DUC 2003,  2004,  and 2005 systems and produces very good correlations with human judgments
one or more model   reference   summaries
The method is similar in nature to Basic Elements   Hovy et al,  2005  ,  in that it extends beyonda simple string comparison of word sequences,  reaching instead to a deeper linguistic analysis of the text
Using a re ranking reran king parser and a LexicalFunctional Grammar   LFG   annotation,  we produce as et of dependency triples for each summary
The dependency set for each candidate summary is then automatically compared against dependencies generated from model summaries
We examine an umber of variations of the method,  including the addition of WordNet,  partial matching,  or removing relation labels from the dependencies
In a teston TAC 2008 and DUC 2007 data,  DEPEVAL   summ   achieves comparable or higher correlations with human judgments than the popular evaluation metricsROUGE and Basic Elements   BE
Both methods use handwritten extraction rules to derive dependencies from constituent parses produced by widely available PennII Tree bank parsers
The difference betweenDEPEVAL   summ   and BE is that in DEPEVAL   summ   the dependency extraction is accomplished through an LFG annotation of Ca hill et al     2004   applied to the output of the rerankingparser of Charniak and Johnson   2005  ,  whereas in BE   in the version presented here   dependencies are generated by the Mini par parser   Lin,  1995
Despite relying on a the same concept,  our approach outperforms BE in most comparisons,  and it often achieves higher correlations with human judgments than the string matching metricROUGE   Lin,  2004   A more detailed description of BE and ROUGEis presented in Section 2,  which also gives an account of manual evaluation methods employed atTAC 2008
Section 3 gives a short introduction to the tot he LFG annotation
Section 4 describes in more detail DEPEVAL   summ   and its variants
Section 5 presents the experiment in which we compared the perfomance of all three metrics on theTAC 2008 data   consisting of 5,  952 words summaries   and on the DUC 2007 data   1,  word summaries   and discusses the correlations these metrics achieve
Finally,  Section presents conclusions and some directions for future work
This paper presents DEPEVAL   summ  ,  a dependency based metric for automatic evaluation of summaries
Abs tractive summarization is an ideal form of summarization since it can synthesize information from multiple documents to create concise informative summaries
In this work,  we aim at developing an abs tractive summarizer
First,  our proposed approach identifies the most important document in the multi document set
The sentences in the most important document are aligned to sentences in other documents to generate clusters of similar sentences
Second,  we generate Kshortest paths from the sentences in each cluster using a word graph structure
Finally,  we select sentences from the set of shortest paths generated from all the clusters employing a novel integer linear programming   ILP   model with the objective of maximizing information content and readability of the final summary
Our ILP model represents the shortest paths as binary variables and considers the length of the path,  information score and linguistic quality score in the objective function
Experimental results on the DUC 2004 and 2005 multi document summarization data sets show that our proposed approach outperforms all the baselines and stateoftheart extractive summarizers as measured by the ROUGE scores
Our method also outperforms a recent abs tractive summarization technique
In manual evaluation,  our approach also achieves promising results on informativeness and readability
8.2-tQuality evaluation9-tEvaluation results
8.3-tAsiya, an evaluation toolkit
We provide an analysis of current evaluation methodologies applied to summarization metrics and identify the following areas of concern
1   movement away from evaluation by correlation with human assessment   2   omission of important components of human assessment from evaluations,  in addition to large numbers of metric variants   3   absence of methods of significance testing improvements over a baseline
We outline an evaluation methodology that overcomes all such challenges,  providing the first method of significance testing suitable for evaluation of summarization metrics
Our evaluation reveals for the first time which metric variants significantly outperform others,  optimal metric variants distinct from current recommended best variants,  as well as machine translation metric BLEU to have performance on par with ROUGE for the purpose of evaluation of summarization systems
We subsequently replicate a recent large scale evaluation that relied on,  what we now know to be,  suboptimal ROUGE variants revealing distinct conclusions about the relative performance of stateoftheart summarization systems
8.4-tText summarization evaluation programs
We provide an analysis of current evaluation methodologies applied to summarization metrics and identify the following areas of concern
1   movement away from evaluation by correlation with human assessment   2   omission of important components of human assessment from evaluations,  in addition to large numbers of metric variants   3   absence of methods of significance testing improvements over a baseline
We outline an evaluation methodology that overcomes all such challenges,  providing the first method of significance testing suitable for evaluation of summarization metrics
Our evaluation reveals for the first time which metric variants significantly outperform others,  optimal metric variants distinct from current recommended best variants,  as well as machine translation metric BLEU to have performance on par with ROUGE for the purpose of evaluation of summarization systems
We subsequently replicate a recent large scale evaluation that relied on,  what we now know to be,  suboptimal ROUGE variants revealing distinct conclusions about the relative performance of stateoftheart summarization systems
Text Summarization is condensing the source text into a shorter version preserving its information content and overall meaning
It is very difficult for human beings to manually summarize large documents of text
Text Summarization methods can be classified into extractive and abs tractive summarization
An extractive summarization method consists of selecting important sentences,  paragraphs etc   from the original document and concatenating them into shorter form
The importance of sentences is decided based on statistical and linguistic features of sentences
An abs tractive summarization method consists of understanding the original text and retelling it in fewer words
It uses linguistic methods to examine and interpret the text and then to find the new concepts and expressions to best describe it by generating a new shorter text that conveys the most important information from the original text document
In this paper,  a Survey of Text Summarization Extractive techniques has been presented
Multi document summarization is a fundamental tool for document understanding and has received much attention recently
Given a collection of documents,  a variety of summarization methods based on different strategies have been proposed to extract the most important sentences from the original documents
However,  very few studies have been reported on aggregating different summarization methods to possibly generate better summary results
In this paper,  we propose a weighted consensus summarization method to combine the results from single summarization systems
We evaluate and compare our proposed weighted consensus method with various baseline combination methods
Experimental results on DUC2002 and DUC2004 data sets demonstrate the performance improvement by aggregating multiple summarization systems,  and our proposed weighted consensus summarization method outperforms other combination methods
The Internet provides many sources of different opinions,  expressed through user reviews of products,  blogs,  and forum discussions
Systems which could automatically summarize these opinions would be immensely useful for those who wish to use this information to make decisions
The previous work in automatic summarization has completely focused on extractive summarization,  in which key sentences are identified from the source text and extracted to form the output
An alternative solution is abs tractive summarization in which the information from the source text is first extracted into the form of abstract data which is then post processed to infer the most important message from the original text
This work is built upon past work of extractive summarization methods to create abs tractive summaries by creating new sentences in it
This paper conveys the methodology for the abs tractive summarization process and its evaluation considering Telugu,  a south Indian regional language,  as the language of study
We present two approaches to email thread summarization collective message summarization   CMS   applies a multi document summarization approach,  while individual message summarization   IMS   treats the problem as a sequence of single document summarization tasks
Both approaches are implemented in our general framework driven by sentence compression
Instead of a purely extractive approach,  we employ linguistic and statistical methods to generate multiple compressions,  and then select from those candidates to produce a final summary
We demonstrate these ideas on the Enron email collection – a very challenging corpus because of the highly technical language
Experimental results point to two findings that CMS represents a better approach to email thread summarization,  and that current sentence compression techniques do not improve summarization performance in this genre
This paper describes a text mining tool that performs two tasks,  namely document clustering and text summarization
These tasks have,  of course,  their corresponding counterpart in “ conventional data mining
However,  the textual,  unstructured nature of documents makes these two text mining tasks considerably more difficult than their data mining counterparts
In our system document clustering is performed by using the Autoclassdata mining algorithm
Our text summarization algorithm is based on computing the value of aTFISF   term frequency – inverse sentence frequency   measure for each word,  which is an adaptation of the conventional TFIDF   term frequency – inverse document frequency   measure of information retrieval
Sentences with high values of TFISF are selected to producea summary of the source text
The system has been evaluated on real world documents,  and the results are satisfactory
In this paper,  we consider document summarization as a multi objective optimization problem involving four objective functions,  namely information coverage,  significance,  redundancy and text coherence
These functions measure the possible summaries based on the identified core terms and main topics   i e a cluster of semantically or statistically related core terms
9-tEvaluation results
10-Future directions in text summarization
REFERENCE
False Abuobieda et-al. 2012 Abuobieda A, Salim N, Albaham AT, Osman AH, Kumar YJ (2012) Text summarization features selection method using pseudo genetic-based model. In: International conference on information retrieval knowledge management, pp 193–197
0005 Aliguliyev 2009 Aliguliyev RM (2009) A new sentence similarity measure and sentence based extractive technique for automatic text summarization. Expert Syst Appl 36(4):7764–7772
0068 Alguliev et-al. 2013 Alguliev RM, Aliguliyev RM, Isazade NR (2013) Multiple documents summarization based on evolutionary optimization algorithm. Expert Syst Appl 40:1675–1689. doi:
0058 Alguliev et-al. 2011 Alguliev RM, Aliguliyev RM, Hajirahimova MS, Mehdiyev CA (2011) MCMR: maximum coverage and minimum redundant text summarization model. Expert Syst Appl 38:14514–14522. doi:
0038 Almeida and Martins 2013 Almeida M, Martins AF (2013) Fast and robust compressive summarization with dual decomposition and multi-task learning. In: ACL (1), pp 196–206
0074 Amigo et-al. 2005 Amigó E, Gonzalo J, Penas A, Verdejo F (2005) QARLA: a framework for the evaluation of text summarization systems. In: ACL ’05: proceedings of the 43rd annual meeting on association for computational linguistics, pp 280–289
0000 Antiqueira et-al. 2009 Antiqueira L, Oliveira ON, Costa F, Volpe G (2009) A complex network approach to text summarization. Inf Sci 179:584–599. doi:
0007 Azmi AM, Al-Thanyyan S 2012 Azmi AM, Al-Thanyyan S (2012) A text summarizer for Arabic. Comput Speech Lang 26:260–273. doi:
0088 Bairi et-al. 2015 Bairi RB, Iyer R, Ramakrishnan G, Bilmes J (2015) Summarization of multi-document topic hierarchies using submodular. In: Proceedings of the 53rd annual meeting of the association for computational linguistics and the 7th international joint conference on natural language processing, pp 553–563
0062 Banerjee et-al. 2015 Banerjee S Mitra P, Sugiyama K (2015) Multi-document abstractive summarization using ILP based multi-sentence compression. In: Proceedings of the 24th international joint conference on artificial intelligence (IJCAI 2015), pp 1208–1214
0065 Baralis et-al. 2012 Baralis E, Cagliero L, Jabeen S, Fiori A (2012) Multi-document summarization exploiting frequent itemsets. In: Symposium on applied computing (SAC’12), pp 782–786
0044 Baralis et-al. 2013 Baralis E, Cagliero L, Mahoto N, Fiori A (2013) GRAPHSUM : discovering correlations among multiple terms for graph-based summarization. Inf Sci 249:96–109. doi:
0024 Barrera and Verma 2012 Barrera A, Verma R (2012) Combining syntax and semantics for automatic extractive single-document summarization. In: 13th international conference on computational linguistics and intelligent text processing. Springer, pp 366–377
0061 Barzilay and Lapata 2005 Barzilay R, Lapata M (2005) Modeling local coherance: an entity-based approach. In: Proceedings of the 43rd annual meeting of the association for computational linguistics (ACL ’05), pp 141–148
0008 Bing et-al. 2015 Bing L, Li P, Liao Y, Lam W, Guo W, Passonneau RJ (2015) Abstractive multi-document summarization via phrase selection and. arXiv preprint 
0052 Boudin F, Morin E 2013 Boudin F, Morin E (2013) Keyphrase extraction for N-best reranking in multi-sentence compression. In: North American Chapter of the Association for Computational Linguistics (NAACL)
0099 Brin and Page 1998 Brin S, Page L (1998) The anatomy of a large scale hypertextual web search engine. In: Proceedings of the 7th international conference on world wide web 7, pp 107–117
0076 Cao et-al. 2015a Cao Z, Wei F, Dong L, Li S, Zhou M (2015a) Ranking with recursive neural networks and its application to multi-document summarization. In: Twenty-ninth AAAI conference on artificial intelligence
0054 Cao et-al. 2015c Cao Z, Wei F, Li S, Li W, Zhou M, Wang H (2015c) Learning summary prior representation for extractive summarization. In: Proceedings of ACL: short papers, pp 829–833
0101 Carbonell and Goldstein 1998 Carbonell JG, Goldstein J (1998) The use of MMR, diversity-based re-ranking for re-ordering documents and producing summaries. In: Proceedings of the 21st annual international ACM SIGIR conference on research and development in information retrieval, pp 335–336
0090 Carenini et-al. 2007 Carenini G, Ng RT, Zhou X (2007) Summarizing email conversations with clue words. In: Proceedings of the 16th international conference on World Wide Web. ACM. pp 91–100
0091 Carenini et-al. 2008 Carenini G, Ng RT, Zhou X (2008) Summarizing emails with conversational cohesion and subjectivity. ACL 8:353–361
0020 Carlson et-al. 2003 Carlson L, Marcu D, Okurowski ME (2003) Building a discourse-tagged corpus in the framework of rhetorical structure theory. Springer, Netherlands, pp 85–112
0018 Chan 2006 Chan SWK (2006) Beyond keyword and cue-phrase matching: a sentence-based abstraction technique for information extraction. Decis Support Syst 42:759–777. doi:
0075 Dunlavy et-al. 2007 Dunlavy DM, O’Leary DP, Conroy JM, Schlesinger JD (2007) A system for querying, clustering and summarizing documents. Inf Process Manag 43:1588–1605
0102 Fang et-al. 2015 Fang H, Lu W, Wu F et al (2015) Topic aspect-oriented summarization via group selection. Neurocomputing 149:1613–1619. doi:
0042 Fattah and Ren 2009 Fattah MA, Ren F (2009) GA, MR, FFNN, PNN and GMM based models for automatic text summarization. Comput Speech Lang 23:126–144. doi:
0014 Ferreira et-al. 2013 Ferreira R, De Souza L, Dueire R et al (2013) Assessing sentence scoring techniques for extractive text summarization. Expert Syst Appl 40:5755–5764. doi:
0003 Ferreira et-al. 2014 Ferreira R, de Souza Cabral L, Freitas F et al (2014) A multi-document summarization system based on statistics and linguistic treatment. Expert Syst Appl 41:5780–5787. doi:
0021 Frank et-al. 2012 Frank JR, Kleiman-Weiner M, Roberts DA, Niu F, Zhang C, Re C, Soboroff I (2012) Building an entity-centric stream filtering test collection for TREC 2012. MASSACHUSETTS INST OF TECH CAMBRIDGE
0070 Fung P, Ngai G 2006 Fung P, Ngai G (2006) One story, one flow: hidden Markov Story Models for multilingual multidocument summarization. ACM Trans Speech Lang 3:1–16. doi:
0072 Ganesan et-al. 2010 Ganesan K, Zhai C, Han J (2010) Opinosis : a graph-based approach to abstractive summarization of highly redundant opinions. In: Proceedings of the 23rd international conference on computational linguistics, pp 340–348
0040 Genest PE, Lapalme G 2011 Genest PE, Lapalme G (2011) Framework for abstractive summarization using text-to-text generation. In: Proceedings of the workshop on monolingual text-to-text generation, Association for Computational Linguistics, pp 64–73
0089 Giannakopoulos et-al. 2008 Giannakopoulos G, Karkaletsis V, Vouros G, Stamatopoulos P (2008) Summarization system evaluation revisited: N-gram graphs. ACM Trans Speech Lang Process 5:1–39
0037 Glavaš G, Šnajder J 2014 Glavaš G, Šnajder J (2014) Event graphs for information retrieval and multi-document summarization. Expert Syst Appl 41:6904–6916. doi:
0064 Goldstein et-al. 2000 Goldstein J, Mittal V, Carbonelll J, Kantrowitz M (2000) Multi-document summarization by sentence extraction. In: NAACL-ANLP 2000 workshop on automatic summarization. pp 40–48
0077 Graham 2015 Graham Y (2015) Re-evaluating automatic summarization with BLEU and 192 shades of ROUGE. In: Proceedings of the 2015 conference on empirical methods in natural language processing. pp 128–137
0022 Grosz et-al. 1995 Grosz BJ, Weinstein S, Joshi AK (1995) Centering: a framework for modeling the local coherence of discourse. Comput Linguist 21:203–225
0045 Gupta V 2013 Gupta V (2013) Hybrid algorithm for multilingual summarization of Hindi and Punjabi documents. In: Mining intelligence and knowledge exploration. Springer International Publishing, pp 717–727
0006 Gupta and Lehal 2010 Gupta V, Lehal GS (2010) A survey of text summarization extractive techniques. J Emerg Technol Web Intell 2:258–268. doi:
0092 Gupta et-al. 2011 Gupta P, Pendluri VS, Vats I (2011) Summarizing text by ranking texts units according to shallow linguistic features. In: 13th international conference on advanced communication technology. pp 1620–1625
0105 Hadi et-al. 2006 Hadi Y, Essannouni F, Thami ROH (2006) Unsupervised clustering by k-medoids for video summarization. In: ISCCSP’06 (the second international symposium on communications, control and signal processing)
0108 Harabagiu S, Lacatusu F 2005 Harabagiu S, Lacatusu F (2005) Topic themes for multi-document summarization. In: SIGIR’ 05: proceedings of the 28th annual international ACM SIGIR conference on research and development in information retrieval. pp 202–209
0031 He et-al. 2012 He Z, Chen C, Bu J, Wang C, Zhang L, Cai D, He X (2012) Document summarization based on data reconstruction. In: AAAI
0098 Hearst 1997 Hearst M (1997) TextTiling: segmenting text into multi-paragraph subtopic passages. Comput Linguist 23:33–64
0039 Heu et-al. 2015 Heu JU, Qasim I, Lee DH (2015) FoDoSu: multi-document summarization exploiting semantic analysis based on social Folksonomy. Inf Process Manag 51(1):212–225
0087 Hirao et-al. 2013 Hirao T, Yoshida Y, Nishino M, Yasuda N, Nagata M (2013) Single-document summarization as a tree knapsack problem. EMNLP 13:1515–1520
0048 Hong and Nenkova 2014 Hong K, Nenkova A (2014) Improving the estimation of word importance for news multi-document summarization. In: Proceedings of EACL
0095 Hong et-al. 2015 Hong K, Marcus M, Nenkova A (2015) System combination for multi-document summarization. In: Proceedings of the 2015 conference on empirical methods in natural language processing. pp 107–117
0015 Hovy et-al. 2006 Hovy E, Lin CY, Zhou L, Fukumoto J (2006) Automated summarization evaluation with basic elements. In: Proceedings of the 5th international conference on language resources and evaluation (LREC), pp 81–94
0060 Huang et-al. 2010 Huang L, He Y, Wei F, Li W (2010) Modeling document summarization as multi-objective optimization. In: Proceedings of the third international symposium on intelligent information technology and security informatics, pp 382–386
0069 Kabadjov et-al. 2010 Kabadjov M, Atkinson M, Steinberger J et al. (2010) NewsGist: a multilingual statistical news summarizer. Lecture notes in computer science (including including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics) 6323 LNAI, pp 591–594. doi:
0084 Kaljahi et-al. 2014 Kaljahi R, Foster J, Roturier J (2014) Semantic role labelling with minimal resources: experiments with french. In: Lexical and computational semantics (*SEM 2014), p 87
0049 Kallimani et-al. 2011 Kallimani JS, Srinivasa KG, Eswara Reddy B (2011) Information extraction by an abstractive text summarization for an Indian regional language. In: Natural language processing and knowledge engineering (NLP-KE), 2011 7th international conference on IEEE, pp 319–322
0073 Kedzie et-al. 2015 Kedzie C, McKeown K, Diaz F (2015) Predicting salient updates for disaster summarization. In: Proceedings of the 53rd annual meeting of the ACL and the 7th international conference on natural language processing. pp 1608–1617
0001 Khan et-al. 2015 Khan A, Salim N, Jaya Kumar Y (2015) A framework for multi-document abstractive summarization based on semantic role labelling. Appl Soft Comput 30:737–747. doi:
0016 Kim and Hovy 2005 Kim SM, Hovy E (2005) Automatic detection of opinion bearing words and sentences. In: Companion volume to the proceedings of the international joint conference on natural language processing (IJCNLP), pp 61–66
0056 Ko and Seo 2004 Ko Y, Seo J (2004) Learning with unlabeled data for text categorization using a bootstrapping and a feature projection technique. In: Proceedings of the 42nd annual meeting of the association for computational linguistics (ACL 2004). pp 255–262
0103 Ko et-al. 2003 Ko Y, Kim K, Seo J (2003) Topic keyword identification for text summarization using lexical clustering. IEICE Trans Inf Syst E86-D:1695–1701
0027 Kulesza and Taskar 2012 Kulesza A, Taskar B (2012) Determinantal point processes for machine learning. arXiv preprint 
0047 Kulkarni and Prasad 2010 Kulkarni UV, Prasad RS (2010) Implementation and evaluation of evolutionary connectionist approaches to automated text summarization. J Comput Sci 6:1366–1376
0055 Lee and Seung 1999 Lee DD, Seung HS (1999) Learning the parts of objects by non-negative matrix factorization. Nature 401(6755):788–791
0082 Leite and Rino 2006 Leite DS, Rino LHM (2006) Selecting a feature set to summarize texts in Brazilian Portuguese. Advances in artificial intelligence-IBERAMIA-SBIA 2006:462–471
0036 Li et-al. 2007 Li JW, Ng KW, Liu Y, Ong KL (2007) Enhancing the effectiveness of clustering with spectra analysis. IEEE Trans Knowl Data Eng 19:887–902
0033 Li et-al. 2013 Li C, Liu F, Weng F, Liu Y (2013) Document summarization via guided sentence compression. In: EMNLP, pp 490–500
0106 Li et-al. 2015a Li C, Liu Y, Zhao L (2015a) Using external resources and joint learning for bigram weighting in ilp-based multi-document summarization. In: Proceedings of NAACL-HLT, pp 778–787
0078 CR92 Li P, Bing L, Lam W, Li H, Liao Y (2015b) Reader-aware multi-document summarization via sparse coding. arXiv preprint 
0080 Lin 2004 Lin CY (2004) ROUGE: a package for automatic evaluation of summaries. In: Proceedings of ACL text summarization workshop, pp 74–81
0066 Lin and Bilmes 2010 Lin H, Bilmes J (2010) Multi-document summarization via budgeted maximization of submodular functions. In: Human language technologies: the 2010 annual conference of the North American chapter of the association for computational linguistics, Association for Computational Linguistics, pp 912–920
0010 Liu et-al. 2009 Liu X, Webster JJ, Kit C (2009) An extractive text summarizer based on significant words. In: Proceedings of the 22nd international conference on computer processing of oriental languages, language technology for the knowledge-based economy, Springer, pp 168–178
0063 Liu et-al. 2015 Liu H, Yu H, Deng ZH (2015) Multi-document summarization based on two-level sparse representation model. In: Twenty-ninth AAAI conference on artificial intelligence
0011 CR100 Lloret E, Palomar M (2011a) Analyzing the use of word graphs for abstractive text summarization. In: IMMM 2011, first international conference, pp 61–66
0100 Luhn 1958 Luhn H (1958) The automatic creation of literature abstracts. IBM J Res Dev 2:159–165
0009 Mani and Maybury 1999 Mani I, Maybury M (1999) Advances in automatic text summarization. MIT Press, Cambridge
0097 Mihalcea and Tarau 2004 Mihalcea R, Tarau P (2004) TextRank: bringing order into texts. In: Conference on empirical methods in natural language processing. pp 404–411
0083 Moawad IF, Aref M 2012 Moawad IF, Aref M (2012) Semantic graph reduction approach for abstractive Text Summarization. In: Proceedings of ICCES 2012, 2012 International Conference on Computer Engineering and Systems, pp 132–138. doi:
0013 Murdock 2006 Murdock VG (2006) Aspects of sentence retrieval. University of Massachusetts, Amherst
0029 Neto et-al. 2000 Neto JL, Santos AD, Kaestner CAA, Freitas AA (2000) Document clustering and text summarization. In: Proceedings of the fourth international conference practical applications of knowledge discovery and data mining (padd-2000), pp 41–55
0085 Nobata et-al. 2001 Nobata C, Satoshi S, Murata M, Uchimoto K, Utimaya M, Isahara H (2001) Sentence extraction system asssembling multiple evidence. In: Proceedings 2nd NTCIR workshop, pp 319–324
0019 Otterbacher et-al. 2009 Otterbacher J, Erkan G, Radev DR (2009) Biased LexRank: passage retrieval using random walks with question-based priors. Inf Process Manag 45(1):42–54
0012 Ouyang et-al. 2011 Ouyang Y, Li W, Li S, Lu Q (2011) Applying regression models to query-focused multi-document summarization. Inf Process Manag 47:227–237
0025 Owczarzak K 2009 Owczarzak K (2009) DEPEVAL summ: dependency-based evaluation for automatic summaries. In: Proceedings of the joint conference of the 47th annual meeting of the ACL and the 4th international joint conference on natural language processing of the AFNLP. pp 190–198
0071 Pang and Lee 2008 Pang B, Lee L (2008) Opinion mining and sentiment analysis. Found Trends Inf Retr 2:1–135
0043 Pardo et-al. 2003b Pardo TAS, Rino LHM, Nunes MGV (2003b) Gistsumm: a summarization tool based on a new extractive method. In: Proceedings of the sixth workshop on computational processing of written and spoken portuguese (propor), 2721 of LNAI, pp 210–218
0051 Parveen and Strube 2015 Parveen D, Strube M (2015) Integrating importance, non-redundancy and coherence in graph-based extractive summarization. In: Proceedings of the 24th international conference on artificial intelligence. AAAI Press. pp 1298–1304
0002 Patel et-al. 2007 Patel A, Siddiqui T, Tiwary US (2007) A language independent approach to multilingual text summarization. In: Large scale semantic access to content (text, image, video, and sound), pp 123–132
0109 Radev et-al. 2001 Radev DR, Fan W, Zhang Z, Arbor A (2001) WebInEssence: a personalized web-based multi-document summarization and recommendation system. In: NAACL 2001 workshop on automatic summarization, pp 79–88
0059 Radev et-al. 2004a Radev D, Allison T, Goldensohn B et al. (2004a) MEAD: a platform for multidocument multilingual text summarization. Proc Lr, 1–4
0023 CR132 Radev DR, Jing HY, Stys M, Tam D (2004b) Centroid-based summarization of multiple documents. Inf Process Manag 40:919–938
0057 Riedhammer et-al. 2010 Riedhammer K, Favre B, Hakkani-Tur D (2010) Long story short- global unsupervised models for keyphrase based meeting summarization. Speech Commun 52:801–815
0093 Rino and Modolo 2004 Rino LHM, Modolo M (2004) Supor: an environment for as of texts in brazilianportuguese. In: Espana for natural language processsing (EsTAL). pp 419–430
0004 Rush et-al. 2015 Rush AM, Chopra S, Weston J (2015) A neural attention model for abstractive sentence summarization. arXiv preprint 
0026 Sanderson M, Croft WB 1999 Sanderson M, Croft WB (1999) Deriving concept hierarchies from text. Proceedings of SIGIR 1999:206–213
0094 Sarkar 2010 Sarkar K (2010) Syntactic trimming of extracted sentences for improving extractive multi-document summarization. J Comput 2:177–184
0050 Shen et-al. 2011 Shen C, Li T, Ding CH (2011) Integrating clustering and multi-document summarization by bi-mixture probabilistic latent semantic analysis PLSA with sentence bases. In: AAAI
0032 Shen et-al. 2007 Shen D, Sun J-T, Li H et al. (2007) Document summarization using conditional random fields. In: Proceedings of 20th international joint conference on artificial intelligence. pp 2862–2867
0081 Simon et-al. 2007 Simon I, Snavely N, Seitz SM (2007) Scene summarization for online image collections. In: Computer vision, 2007. ICCV 2007. IEEE 11th international conference on. IEEE. pp 1–8
0053 Sipos et-al. 2012 Sipos R, Shivaswamy P, Joachims T (2012) Large-margin learning of submodular summarization models. In: Proceedings of the 13th conference of the European chapter of the association for computational linguistics, Association for Computational Linguistics, pp 224–233
0041 Song et-al. 2011 Song W, Choi LC, Park SC, Ding XF (2011) Fuzzy evolutionary optimization modeling and its applications to unsupervised categorization and extractive summarization. Expert Syst Appl 38:9112–9121
0028 Storn R, Price K 1997 Storn R, Price K (1997) Differential evolution-a simple and efficient heuristic for global optimization over continuous spaces. J Glob Optim 11(4):341–359
0110 Wang and Li 2012 Wang D, Li T (2012) Weighted consensus multi-document summarization. Inf Process Manag 48:513–523
0046 Yang et-al. 2013 Yang C, Shen J, Peng J, Fan J (2013) Image collection summarization via dictionary learning for sparse representation. Pattern Recognit 46(3):948–961
0034 Yang et-al. 2014 Yang L, Cai X, Zhang Y, Shi P (2014) Enhancing sentence-level clustering with ranking-based clustering framework for theme-based summarization. Inf Sci 260:37–50. doi:
0030 Ye et-al. 2007 Ye S, Chua TS, Kan MY, Qiu L (2007) Document concept lattice for text understanding and summarization. Inf Process Manag 43:1643–1662. doi:
0096 Yeh et-al. 2005 Yeh J-Y, Ke H-R, Yang W-P, Meng I-H (2005) Text summarization using a trainable summarizer and latent semantic analysis. Inf Process Manag 41:75–95. doi:
0086 Zajic et-al. 2008 Zajic DM, Dorr BJ, Lin J (2008) Single-document and multi-document summarization techniques for e-mail threads using sentence compression. Inf Process Manag 44:1600–1610
0107 Zhao et-al. 2009 Zhao L, Wu L, Huang X (2009) Using query expansion in graph-based approach for query-focused multi-document summarization. Inf Process Manag 45(1):35–41
