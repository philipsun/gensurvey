root
Recent automatic text summarization techniques: a survey
1-tIntroduction
1.1-tNeed of text summarization
In  Harabagiu S, Lacatusu F 2005: 
We present eight different methods of generating multi document summaries and evaluate each of these methods on a large set of topics used in past DUC workshops
Our evaluation results show a significant improvement in the quality of summaries based on topic themes over MDS methods that use other alternative topic representations
2-tVarious types of text Summarization
In  Zajic et-al. 2008: 
We demonstrate these ideas on the Enron email collection â€“ a very challenging corpus because of the highly technical language
Both approaches are implemented in our general framework driven by sentence compression
In  Fattah and Ren 2009: 
This approach is a trainable summarizer,  which takes into account several features,  including sentence position,  positive keyword,  negative keyword,  sentence centrality,  sentence resemblance to the title,  sentence inclusion of name entity,  sentence inclusion of numerical data,  sentence relative length,  Bushy path of the sentence and aggregated similarity for each sentence to generate summaries
Moreover,  we use all feature parameters to train feed forward neural network   FFNN  ,  probabilistic neural network   PNN   and Gaussian mixture model   GMM   in order to construct a text summarizer for each model
The results of the proposed approach are promising,  especially the GMM approach
In  Sarkar 2010: 
Multi document summaries can enable the users to identify the main theme   central idea   of a cluster of texts very rapidly
For our experiments,  we develop   1   a primary summarization system,  which extracts sentences to form a draft summary and   2   a trimming component,  which accepts a draft summary for revision
Our test results on DUC 2004 data set show that the summarization system,  which integrates both the extraction component and the trimming component,  performs better than some stateofthe art summarization approaches
In  Dunlavy et-al. 2007: 
Under this framework,  we then demonstrate that the QCS system   endtoend   achieves performance as good as or better than the best summarization engines
Given a query,  QCS retrieves relevant documents,  separates the retrieved documents into topic clusters,  and creates a single summary for each cluster
Our system demonstrates the feasibility of assembling an effective IR system from existing software libraries,  the usefulness of the modularity of the design,  and the value of this particular combination of modules
Most importantly,  the combination of the three types of methods in the QCS design improves retrievals by providing users more focused information organized by topic
Information retrieval systems consist of many complicated components
In  Riedhammer et-al. 2010: 
Both optimization problems are formulated as an integer linear program   ILP   and solved using public domain software
Multiparty meetings speech Summarization Key phrases Global optimization
All rights reserved
Keywords
In  Song et-al. 2011: 
This paper proposes a fuzzy evolutionary optimization modeling   FEOM   and its applications to unsupervised categorization and extractive summarization
The searching capability of FEOM is exploited to explore appropriate partitions of documents such that the similarity metric of the resulting clusters is optimized
As a portable,  modular and extensively executable model,  FEOM is firstly implemented for clustering text documents
Reuter document collection,  newsgroup corpus,  DUC01 and DUC02,  as evaluated by some commonly used metrics,  i e
Fmeasure and ROUGE
In  Radev et-al. 2001: 
Some evaluation results with di erent con gurations are also presented
WebInEssence
3-tClassification of extractive approaches for summary generation
3.1-tStatistical based approaches
In  Fattah and Ren 2009: 
Furthermore,  we use trained models by one language to test summarization performance in the other language
The proposed approach performance is measured at several compression rates on a data corpus composed of 100 Arabic political articles and 100 English religious articles
The results of the proposed approach are promising,  especially the GMM approach
3.2-tTopic based approaches
In  Hearst 1997: 
Multi paragraph Multipara graph subtopic segmentation should be useful for many text analysis tasks,  including information retrieval and summarization
3.3-tGraph based approaches
In  Baralis et-al. 2013: 
The graph nodes,  which represent combinations of two or more terms,  are first ranked by means of a PageRank strategy that discriminates between positive and negative term correlations
Then,  the produced node ranking is used to drive the sentence selection process
The experiments performed on benchmark and real life documents demonstrate the effectiveness of the proposed approach compared to many stateoftheart summarizers
3.4-tDiscourse based approaches
In  Fattah and Ren 2009: 
Furthermore,  we use trained models by one language to test summarization performance in the other language
Moreover,  we use all feature parameters to train feed forward neural network   FFNN  ,  probabilistic neural network   PNN   and Gaussian mixture model   GMM   in order to construct a text summarizer for each model
The results of the proposed approach are promising,  especially the GMM approach
In  Yang et-al. 2014: 
As the length of sentences is short and the content it contains is limited,  the bagofwords cosine similarity traditionally used for document clustering is no longer reasonably suitable
Special treatment for measuring sentence similarity is necessary
3.5-tApproaches based on machine learning
4-t Recent automatic text summarization extractive approaches
4.1-tTrained summarizer and latent semantic analysis for summarization of text
In  Yeh et-al. 2005: 
We evaluate LSA + T.R.M both with single documents and at the corpus level to investigate the competence of LSA in text summarization
The two novel approaches were measured at several compression rates on a data corpus composed of 100 political articles
When the compression rate was 30%,  an average fmeasure of 49% for MCBA,  52% for MCBA + GA,  44% and 40% for LSA + T.R.M in single document and corpus level were achieved respectively
4.2-tInformation extraction using sentence based abstraction technique
In  Chan 2006: 
Instead,  the attention is focused on the identification of the main factors in the textual continuity
Simulation experiments suggest that this technique is useful because it moves away from a purely keyword based method of textual information extraction and its associated limitations
4.3-tText understanding and summarization through document concept lattice
In  Ye et-al. 2007: 
The local topics will specify the promising subspaces related to the selected concepts and sentences
Based on this lattice,  the summary is an optimized selection of a set of distinct and salient local topics that lead to maximal coverage of concepts with the given number of sentences
Our summarizer based on the concept lattice has demonstrated competitive performance in Document Understanding Conference 2005 and 2006 evaluations as well as follow on tests
4.4-tSentence extraction through contextual information and statistical based summarization of text
In  Ko and Seo 2004: 
We here propose a new automatic text categorization method for learning from only unlabeled data using a bootstrapping framework and a feature projection technique
From results of our experiments,  our method showed reasonably comparable performance compared with a supervised method
If our method is used in a text categorization task,  building text categorization systems will become significantly faster and less expensive
4.5-tSummarization of emails through conversational cohesion and subjective opinions
In  Carenini et-al. 2008: 
In this paper,  we study the problem of summarizing email conversations
The empirical evaluation shows that the basic clue words have the highest accuracy among the three cohesion measures
Moreover,  subjective words can significantly improve accuracy
In  Kim and Hovy 2005: 
We describe a sentence level opinion detection system
MPQA data,  an internal corpus,  and the TREC- 2003 Novelty track data
4.6-tSummarization of text through complex network approach
In  Antiqueira et-al. 2009: 
An additional summarizer was created which selects the highest ranked sentences in the 14 systems,  as in a voting system
When applied to a corpus of Brazilian Portuguese texts,  some CNSumm versions performed better than summarizers that do not employ deep linguistic knowledge,  with results comparable to stateoftheart summarizers based on expensive linguistic resources
The use of complex networks to represent texts appears therefore as suitable for automatic summarization,  consistent with the belief that the metrics of such networks may capture important text features
4.7-tAutomatic creation of generic document summaries through non-negative matrix factorization
4.8-tAutomatic text summarization using MR, GA, FFNN, GMM and PNN based models
In  Fattah and Ren 2009: 
Furthermore,  we use trained models by one language to test summarization performance in the other language
The proposed approach performance is measured at several compression rates on a data corpus composed of 100 Arabic political articles and 100 English religious articles
The results of the proposed approach are promising,  especially the GMM approach
4.9-tQuery-based summarization of multiple documents by applying regression models
In  Carbonell and Goldstein 1998: 
The latter are borne out by the recent results of the SUMMAC conference in the evaluation of summarization systems
However,  the clearest advantage is demonstrated in constructing non redundant multi document summaries,  where MMR results are clearly superior to nonMMR passage selection
4.10-tMaximum coverage and minimum redundancy in summarization of text
In  Alguliev et-al. 2011: 
The proposed model is quite general and can also be used for single and multi document summarization
We implemented our model on multi document summarization task
Experimental results on DUC2005 and DUC2007 data sets showed that our proposed approach outperforms the baseline systems
4.11-tSummarization of documents through a progressive technique for selection of sentences
4.12-tEvaluation of sentence scoring methods for extractive summarization of text
In  Ferreira et-al. 2013: 
It is an important way of finding relevant information in large text libraries or in the Internet
Extractive techniques perform text summarization by selecting sentences of documents according to some criteria
Essentially,  text summarization techniques are classified as Extractive and Abs tractive
Three different data sets   News,  Blogs and Article contexts   were evaluated
In  Lin 2004: 
ROUGE stands for RecallOriented Unde rstudy for Gi sting Evaluation
This paper introduces four different ROUGE measures
In  Fattah and Ren 2009: 
The results of the proposed approach are promising,  especially the GMM approach
Then we use all features in combination to train genetic algorithm   GA   and mathematical regression   MR   models to obtain a suitable combination of feature weights
Moreover,  we use all feature parameters to train feed forward neural network   FFNN  ,  probabilistic neural network   PNN   and Gaussian mixture model   GMM   in order to construct a text summarizer for each model
In  Gupta et-al. 2011: 
As per the limitations of the current summarizing systems,  the summary generated by those systems contains poorly linked sentences and are not topically salient
Our results show that the agreement among the human subjects and our algorithm is highly significant
A threshold angle between the two vectors is predefined experimentally to which the ranked scored sentences to be dropped and which the significant sentences with ranking scores higher than threshold to be extracted
We then identified and extracted high scored sentences and then the Vector Space approach is used to measure the relatedness similarity between the extracted sentence and the topic words involving again the WordNet lexical database relationships to prioritise the topically related sentences
Our research work presents the concept of topic word similarity with the high ranking sentences obtained after applying various heuristics,  lexical chaining and the Vector Space approaches
In  Barrera and Verma 2012: 
These results have implications not only for extractive and abs tractive single document summarization,  but could also be leveraged in multi document summarization
This approach essentially combines syntactic,  semantic,  and statistical methodologies,  and reflects psychological findings that pinpoint specific selection patterns as humans construct summaries
In  Nobata et-al. 2001: 
Results from the TSC formal run showed that our method was effective in the sentence extraction task
In  Mihalcea and Tarau 2004: 
4.13-tExploring correlations among multiple terms through a graph-based summarizer, GRAPHSUM
In  Baralis et-al. 2013: 
It discovers and exploits association rules to represent the correlations among multiple terms that have been neglected by previous approaches
This paper presents a novel and general purpose graph based summarizer,  namely GraphSum   Graph based Summarizer
However,  since the high order correlations among multiple terms are disregarded during graph evaluation,  the summarization performance could be limited unless integrating ad hoc language dependent or semantics based analysis
In  Brin and Page 1998: 
Furthermore,  due to rapid advance in technology and Web proliferation,  creating a Web search engine today is very different from three years ago
To engineer a search engine is a challenging task
Also we look at the problem of how to effectively deal with uncontrolled hypertext collections where anyone can publish anything they want
Despite the importance of large scale search engines on the Web,  very little academic research has been done on them
They answer tens of millions of queries every day
4.14-tIncorporating various levels of language analysis for tackling redundancy in text summarization
4.15-tEvolutionary optimization algorithm for summarizing multiple documents
In  Alguliev et-al. 2013: 
We implemented the proposed model on multi document summarization task
Experiments have been performed on DUC2002 and DUC2004 data sets
The experimental results provide strong evidence that the proposed optimization based approach is a viable method for document summarization
4.16-tSummarization of multiple documents using a hybrid machine learning model
4.17-tImproving clustering at sentence-level with the help of ranking-based technique for theme-based summarization
In  Yang et-al. 2014: 
In this paper,  we propose a ranking based clustering framework that utilizes ranking distribution of documents and terms to help generate high quality sentence clusters
The effectiveness of the proposed framework is demonstrated by both the cluster quality analysis and the summarization evaluation conducted on the DUC 2004 and DUC2007 data sets
4.18-tStatistical and linguistic based summarization system for multiple documents
In  Ferreira et-al. 2014: 
The massive quantity of data available today in the Internet has reached such a huge volume that it has become humanly unfeasible to efficiently sieve useful information from it
Such a purpose is achieved through a new sentence clustering algorithm based on a graph model that makes use of statistic similarities and linguistic treatment
In  Ferreira et-al. 2013: 
In addition,  directions to improve the sentence extraction results obtained are suggested
Abs tractive summaries attempt to improve the coherence among sentences by eliminating redundancies and clarifying the contest of sentences
Essentially,  text summarization techniques are classified as Extractive and Abs tractive
Three different data sets   News,  Blogs and Article contexts   were evaluated
In  Mihalcea and Tarau 2004: 
4.19-tMulti-document summarization based information retrieval using event graphs
4.20-textractive summarization of single documents through genetic operators and guided local search
4.21-t Topic-aspect based summarization through selection of groups
In  Fang et-al. 2015: 
We compare our proposed approach with some stateoftheart methods on DUC2003,  DUC2004 data sets for text summarization and NUSWide data set for image summarization
The results show our method can generate meaningful summarization in terms of ROUGE and Jensenâ€“Shannon Divergence metrics
4.22-tSummarization of multiple documents based on social Folksonomy by analyzing semantically
In  Heu et-al. 2015: 
Then,  by exploiting tag clusters,  we analyze the semantic relationships between words in the word frequency table
Finally,  we create a summary of multiple documents by analyzing the importance of each word and its semantic relatedness to others
Experimental results from the TAC 2008 and 2009 data sets demonstrate the improvement of our proposed framework over existing summarization systems
4.23-tOther text summarization approaches
4.23.1-tLearning-based approach for summarizing related sentences
4.23.2-tSemantic role labeling with minimal resources
In  Kaljahi et-al. 2014: 
Moreover,  there seems to be no improvement gained from projecting semantic roles between direct translations than between indirect translations
4.23.3-tSummarizing single documents through nested tree structure
4.23.4-tTwo-level sparse representation model for summarization of multiple documents
In  Liu et-al. 2015: 
Coverage,  Sparsity and Diversity
We then for
malize the task of multi document summarization as an optimization problem according to the above properties,  and use simulated annealing algorithm to solve it
Extensive experiments on summarization benchmark data sets DUC2006 and DUC2007 show that our proposed model is effective and outperforms the stateoftheartalgorithms
4.23.5-tSparse-coding based reader-aware summarization system for multiple documents
In  Li et-al. 2015a: 
The core idea of this summarization method is to select the summary sentences by maximizing the sum of the weights of the language concepts that appear in the summary
Bi grams Big rams are often used as these language concepts because Gil lick et al     2009   stated that the bi grams big rams gave consistently better performance than uni grams or trigrams for avariety of ROUGE measures
The association between the language concepts and sentences serves as the constraints
This ILP method is formally represented as below   see   Gil lick et al,  2009   for more details
Some stateoftheart summarization systems use integer linear programming   ILP   based methods that aim to maximize the important concepts covered in the summary
These concepts are often obtained by selecting bigramsfrom the documents
In this paper,  we improve such bi gram big ram based ILP summarization methods from different aspects
4.23.6-tSummarization of multiple documents through recursive neural networks based ranking approach
In  Cao et-al. 2015a: 
Hierarchical regressions are then conducted with learned features concatenating raw features
Ranking scores of sentences and words are utilized to effectively select informative and non redundant sentences to generate summaries
Experiments on the DUC 2001,  2002 and 2004 multi document summarization data sets show that R2N2 outperforms stateoftheart extractive summarization approaches
4.23.7-tGraph-based extractive summarization by considering importance, non-redundancy and coherence
In  Parveen and Strube 2015: 
We compare ROUGE scores and human judgements for coherence of different systems on scienti c articles
Our method performs considerably better than other systems on this data
Also,  our graphbasedsummarization technique achieves stateoftheartresults on DUC 2002 data
Incorporating our local coherence measure always achieves the best results
4.23.8-tSparse optimization based compressive document summarization
4.23.9-t Submodular mixtures based summarization of multi-document hierarchy of topics
In  Bairi et-al. 2015: 
We use a large margin framework to learn convex mixtures over the set of sub modular components
We empirically evaluate our method on the problem of automatically generating Wikipedia disambiguation pages using human generated clusterings as ground truth
We find that our framework improves upon several baselines according to a variety of standard evaluation metrics including the Jaccard Index,  F score and NMI,  and moreover,  can be scaled to extremely large scale problems
4.23.10-tDisaster summarization through prediction of salient updates
In  Kedzie et-al. 2015: 
We use novel,  disaster specific features for salience prediction,  including geolocations and language models representing the language of disaster
Our evaluation on a standard set of retrospective events using ROUGE shows that salience prediction provides a significant improvement over other approaches
4.23.11-tSummarizing multiple documents through system combination
In  Hong et-al. 2015: 
The model relies on a rich set of features that capture content importance from different perspectives
Our model performs better than the systems that we combined based on manual and automatic evaluations
We also achieve very competitive performance on six DUC/TAC data sets,  comparable to the stateoftheart on most data sets
4.23.12-tPhrase-based compressive cross-language summarization
4.23.13-t Re-evaluation of automatic summarization using BLEU and 192 variants of ROUGE
In  Graham 2015: 
Our evaluation reveals for the first time which metric variants significantly outperform others,  optimal metric variants distinct from current recommended best variants,  as well as machine translation metric BLEU to have performance on par with ROUGE for the purpose of evaluation of summarization systems
We subsequently replicate a recent large scale evaluation that relied on,  what we now know to be,  suboptimal ROUGE variants revealing distinct conclusions about the relative performance of stateoftheart summarization systems
4.24-tPro and Cons
5-tComparison of recent automatic text summarization extractive approaches
6-tAbstractive approaches for text summarization
In  Ganesan et-al. 2010: 
The summaries are readable,  reasonably well formed and are informative enough to convey the major opinions
In  Kallimani et-al. 2011: 
The Internet provides many sources of different opinions,  expressed through user reviews of products,  blogs,  and forum discussions
Systems which could automatically summarize these opinions would be immensely useful for those who wish to use this information to make decisions
In  Khan et-al. 2015: 
Results indicate that the proposed approach performs better than other summarization systems
Experiment of this study is carried out using DUC2002,  a standard corpus for text summarization
First,  it employs semantic role labeling for semantic representation of text
In  Banerjee et-al. 2015: 
Our ILP model represents the shortest paths as binary variables and considers the length of the path,  information score and linguistic quality score in the objective function
First,  our proposed approach identifies the most important document in the multi document set
In this work,  we aim at developing an abs tractive summarizer
In manual evaluation,  our approach also achieves promising results on informativeness and readability
In  Bing et-al. 2015: 
Experimental results on the benchmark data set TAC 2011 show that our framework outperforms the stateoftheart models under automated pyramid evaluation metric,  and achieves reasonably well results on manual linguistic quality evaluation
We propose an abstraction based multi document summarization framework that can construct new sentences by exploring more fine grained syntactic units than sentences,  namely,  noun verb phrases
In  Rush et-al. 2015: 
Summarization based on text extraction is inherently limited,  but generation style abs tractive methods have proven challenging to build
The model shows significant performance gains on the DUC2004 shared task compared with several strong baselines
7-tMultilingual approaches for text summarization
In  Radev et-al. 2004a: 
In  Patel et-al. 2007: 
This paper describes an efficient algorithm for language independent generic extractive summarization for single document
Content richness,  Theme features,  Sentence reference index,  Partitioning,  Fuzzy summary,  Coherence,  Degree of representative ness
Key Words
In  Kabadjov et-al. 2010: 
In this paper we present NewsGist,  a multilingual,  multi document news summarization system underpinned by the Singular Value Decomposition   SVD   paradigm for document summarization and purpose built for the Europe Media Monitor   EMM
In  Gupta and Lehal 2010: 
It uses linguistic methods to examine and interpret the text and then to find the new concepts and expressions to best describe it by generating a new shorter text that conveys the most important information from the original text document
It is very difficult for human beings to manually summarize large documents of text
Text Summarization methods can be classified into extractive and abs tractive summarization
In  Giannakopoulos et-al. 2008: 
Automatic summarization,  summarization evaluation,  ngram graph
Natural Language Process ing Text analysis,  language models
Algorithms,  Languages,  Measurement,  Performance
I Ar ti cial Intelligence
General Terms
8-tSummary evaluation
8.1-tInformativeness evaluation
In  Amigo et-al. 2005: 
Compared to previous approaches,  our framework is able to combine different metrics and evaluate the quality of a set of metrics without any apriori weighting of their relative importance
We provide quantitative evidence about the effectiveness of the approach to improve the automatic evaluation of text summarisation systems by combining several similarity metrics
8.2-tQuality evaluation9-tEvaluation results
8.3-tAsiya, an evaluation toolkit
In  Amigo et-al. 2005: 
Compared to previous approaches,  our framework is able to combine different metrics and evaluate the quality of a set of metrics without any apriori weighting of their relative importance
We provide quantitative evidence about the effectiveness of the approach to improve the automatic evaluation of text summarisation systems by combining several similarity metrics
8.4-tText summarization evaluation programs
In  Lin 2004: 
This paper introduces four different ROUGE measures
ROUGE stands for RecallOriented Unde rstudy for Gi sting Evaluation
In  Hovy et-al. 2006: 
This method is tested on DUC 2003,  2004,  and 2005 systems and produces very good correlations with human judgments
9-tEvaluation results
10-Future directions in text summarization
REFERENCE
False Abuobieda et-al. 2012 Abuobieda A, Salim N, Albaham AT, Osman AH, Kumar YJ (2012) Text summarization features selection method using pseudo genetic-based model. In: International conference on information retrieval knowledge management, pp 193â€“197
0005 Aliguliyev 2009 Aliguliyev RM (2009) A new sentence similarity measure and sentence based extractive technique for automatic text summarization. Expert Syst Appl 36(4):7764â€“7772
0068 Alguliev et-al. 2013 Alguliev RM, Aliguliyev RM, Isazade NR (2013) Multiple documents summarization based on evolutionary optimization algorithm. Expert Syst Appl 40:1675â€“1689. doi:
0058 Alguliev et-al. 2011 Alguliev RM, Aliguliyev RM, Hajirahimova MS, Mehdiyev CA (2011) MCMR: maximum coverage and minimum redundant text summarization model. Expert Syst Appl 38:14514â€“14522. doi:
0038 Almeida and Martins 2013 Almeida M, Martins AF (2013) Fast and robust compressive summarization with dual decomposition and multi-task learning. In: ACL (1), pp 196â€“206
0074 Amigo et-al. 2005 AmigÃ³ E, Gonzalo J, Penas A, Verdejo F (2005) QARLA: a framework for the evaluation of text summarization systems. In: ACL â€™05: proceedings of the 43rd annual meeting on association for computational linguistics, pp 280â€“289
0000 Antiqueira et-al. 2009 Antiqueira L, Oliveira ON, Costa F, Volpe G (2009) A complex network approach to text summarization. Inf Sci 179:584â€“599. doi:
0007 Azmi AM, Al-Thanyyan S 2012 Azmi AM, Al-Thanyyan S (2012) A text summarizer for Arabic. Comput Speech Lang 26:260â€“273. doi:
0088 Bairi et-al. 2015 Bairi RB, Iyer R, Ramakrishnan G, Bilmes J (2015) Summarization of multi-document topic hierarchies using submodular. In: Proceedings of the 53rd annual meeting of the association for computational linguistics and the 7th international joint conference on natural language processing, pp 553â€“563
0062 Banerjee et-al. 2015 Banerjee S Mitra P, Sugiyama K (2015) Multi-document abstractive summarization using ILP based multi-sentence compression. In: Proceedings of the 24th international joint conference on artificial intelligence (IJCAI 2015), pp 1208â€“1214
0065 Baralis et-al. 2012 Baralis E, Cagliero L, Jabeen S, Fiori A (2012) Multi-document summarization exploiting frequent itemsets. In: Symposium on applied computing (SACâ€™12), pp 782â€“786
0044 Baralis et-al. 2013 Baralis E, Cagliero L, Mahoto N, Fiori A (2013) GRAPHSUM : discovering correlations among multiple terms for graph-based summarization. Inf Sci 249:96â€“109. doi:
0024 Barrera and Verma 2012 Barrera A, Verma R (2012) Combining syntax and semantics for automatic extractive single-document summarization. In: 13th international conference on computational linguistics and intelligent text processing. Springer, pp 366â€“377
0061 Barzilay and Lapata 2005 Barzilay R, Lapata M (2005) Modeling local coherance: an entity-based approach. In: Proceedings of the 43rd annual meeting of the association for computational linguistics (ACL â€™05), pp 141â€“148
0008 Bing et-al. 2015 Bing L, Li P, Liao Y, Lam W, Guo W, Passonneau RJ (2015) Abstractive multi-document summarization via phrase selection and. arXiv preprint 
0052 Boudin F, Morin E 2013 Boudin F, Morin E (2013) Keyphrase extraction for N-best reranking in multi-sentence compression. In: North American Chapter of the Association for Computational Linguistics (NAACL)
0099 Brin and Page 1998 Brin S, Page L (1998) The anatomy of a large scale hypertextual web search engine. In: Proceedings of the 7th international conference on world wide web 7, pp 107â€“117
0076 Cao et-al. 2015a Cao Z, Wei F, Dong L, Li S, Zhou M (2015a) Ranking with recursive neural networks and its application to multi-document summarization. In: Twenty-ninth AAAI conference on artificial intelligence
0054 Cao et-al. 2015c Cao Z, Wei F, Li S, Li W, Zhou M, Wang H (2015c) Learning summary prior representation for extractive summarization. In: Proceedings of ACL: short papers, pp 829â€“833
0101 Carbonell and Goldstein 1998 Carbonell JG, Goldstein J (1998) The use of MMR, diversity-based re-ranking for re-ordering documents and producing summaries. In: Proceedings of the 21st annual international ACM SIGIR conference on research and development in information retrieval, pp 335â€“336
0090 Carenini et-al. 2007 Carenini G, Ng RT, Zhou X (2007) Summarizing email conversations with clue words. In: Proceedings of the 16th international conference on World Wide Web. ACM. pp 91â€“100
0091 Carenini et-al. 2008 Carenini G, Ng RT, Zhou X (2008) Summarizing emails with conversational cohesion and subjectivity. ACL 8:353â€“361
0020 Carlson et-al. 2003 Carlson L, Marcu D, Okurowski ME (2003) Building a discourse-tagged corpus in the framework of rhetorical structure theory. Springer, Netherlands, pp 85â€“112
0018 Chan 2006 Chan SWK (2006) Beyond keyword and cue-phrase matching: a sentence-based abstraction technique for information extraction. Decis Support Syst 42:759â€“777. doi:
0075 Dunlavy et-al. 2007 Dunlavy DM, Oâ€™Leary DP, Conroy JM, Schlesinger JD (2007) A system for querying, clustering and summarizing documents. Inf Process Manag 43:1588â€“1605
0102 Fang et-al. 2015 Fang H, Lu W, Wu F et al (2015) Topic aspect-oriented summarization via group selection. Neurocomputing 149:1613â€“1619. doi:
0042 Fattah and Ren 2009 Fattah MA, Ren F (2009) GA, MR, FFNN, PNN and GMM based models for automatic text summarization. Comput Speech Lang 23:126â€“144. doi:
0014 Ferreira et-al. 2013 Ferreira R, De Souza L, Dueire R et al (2013) Assessing sentence scoring techniques for extractive text summarization. Expert Syst Appl 40:5755â€“5764. doi:
0003 Ferreira et-al. 2014 Ferreira R, de Souza Cabral L, Freitas F et al (2014) A multi-document summarization system based on statistics and linguistic treatment. Expert Syst Appl 41:5780â€“5787. doi:
0021 Frank et-al. 2012 Frank JR, Kleiman-Weiner M, Roberts DA, Niu F, Zhang C, Re C, Soboroff I (2012) Building an entity-centric stream filtering test collection for TREC 2012. MASSACHUSETTS INST OF TECH CAMBRIDGE
0070 Fung P, Ngai G 2006 Fung P, Ngai G (2006) One story, one flow: hidden Markov Story Models for multilingual multidocument summarization. ACM Trans Speech Lang 3:1â€“16. doi:
0072 Ganesan et-al. 2010 Ganesan K, Zhai C, Han J (2010) Opinosis : a graph-based approach to abstractive summarization of highly redundant opinions. In: Proceedings of the 23rd international conference on computational linguistics, pp 340â€“348
0040 Genest PE, Lapalme G 2011 Genest PE, Lapalme G (2011) Framework for abstractive summarization using text-to-text generation. In: Proceedings of the workshop on monolingual text-to-text generation, Association for Computational Linguistics, pp 64â€“73
0089 Giannakopoulos et-al. 2008 Giannakopoulos G, Karkaletsis V, Vouros G, Stamatopoulos P (2008) Summarization system evaluation revisited: N-gram graphs. ACM Trans Speech Lang Process 5:1â€“39
0037 GlavaÅ¡ G, Å najder J 2014 GlavaÅ¡ G, Å najder J (2014) Event graphs for information retrieval and multi-document summarization. Expert Syst Appl 41:6904â€“6916. doi:
0064 Goldstein et-al. 2000 Goldstein J, Mittal V, Carbonelll J, Kantrowitz M (2000) Multi-document summarization by sentence extraction. In: NAACL-ANLP 2000 workshop on automatic summarization. pp 40â€“48
0077 Graham 2015 Graham Y (2015) Re-evaluating automatic summarization with BLEU and 192 shades of ROUGE. In: Proceedings of the 2015 conference on empirical methods in natural language processing. pp 128â€“137
0022 Grosz et-al. 1995 Grosz BJ, Weinstein S, Joshi AK (1995) Centering: a framework for modeling the local coherence of discourse. Comput Linguist 21:203â€“225
0045 Gupta V 2013 Gupta V (2013) Hybrid algorithm for multilingual summarization of Hindi and Punjabi documents. In: Mining intelligence and knowledge exploration. Springer International Publishing, pp 717â€“727
0006 Gupta and Lehal 2010 Gupta V, Lehal GS (2010) A survey of text summarization extractive techniques. J Emerg Technol Web Intell 2:258â€“268. doi:
0092 Gupta et-al. 2011 Gupta P, Pendluri VS, Vats I (2011) Summarizing text by ranking texts units according to shallow linguistic features. In: 13th international conference on advanced communication technology. pp 1620â€“1625
0105 Hadi et-al. 2006 Hadi Y, Essannouni F, Thami ROH (2006) Unsupervised clustering by k-medoids for video summarization. In: ISCCSPâ€™06 (the second international symposium on communications, control and signal processing)
0108 Harabagiu S, Lacatusu F 2005 Harabagiu S, Lacatusu F (2005) Topic themes for multi-document summarization. In: SIGIRâ€™ 05: proceedings of the 28th annual international ACM SIGIR conference on research and development in information retrieval. pp 202â€“209
0031 He et-al. 2012 He Z, Chen C, Bu J, Wang C, Zhang L, Cai D, He X (2012) Document summarization based on data reconstruction. In: AAAI
0098 Hearst 1997 Hearst M (1997) TextTiling: segmenting text into multi-paragraph subtopic passages. Comput Linguist 23:33â€“64
0039 Heu et-al. 2015 Heu JU, Qasim I, Lee DH (2015) FoDoSu: multi-document summarization exploiting semantic analysis based on social Folksonomy. Inf Process Manag 51(1):212â€“225
0087 Hirao et-al. 2013 Hirao T, Yoshida Y, Nishino M, Yasuda N, Nagata M (2013) Single-document summarization as a tree knapsack problem. EMNLP 13:1515â€“1520
0048 Hong and Nenkova 2014 Hong K, Nenkova A (2014) Improving the estimation of word importance for news multi-document summarization. In: Proceedings of EACL
0095 Hong et-al. 2015 Hong K, Marcus M, Nenkova A (2015) System combination for multi-document summarization. In: Proceedings of the 2015 conference on empirical methods in natural language processing. pp 107â€“117
0015 Hovy et-al. 2006 Hovy E, Lin CY, Zhou L, Fukumoto J (2006) Automated summarization evaluation with basic elements. In: Proceedings of the 5th international conference on language resources and evaluation (LREC), pp 81â€“94
0060 Huang et-al. 2010 Huang L, He Y, Wei F, Li W (2010) Modeling document summarization as multi-objective optimization. In: Proceedings of the third international symposium on intelligent information technology and security informatics, pp 382â€“386
0069 Kabadjov et-al. 2010 Kabadjov M, Atkinson M, Steinberger J et al. (2010) NewsGist: a multilingual statistical news summarizer. Lecture notes in computer science (including including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics) 6323 LNAI, pp 591â€“594. doi:
0084 Kaljahi et-al. 2014 Kaljahi R, Foster J, Roturier J (2014) Semantic role labelling with minimal resources: experiments with french. In: Lexical and computational semantics (*SEM 2014), p 87
0049 Kallimani et-al. 2011 Kallimani JS, Srinivasa KG, Eswara Reddy B (2011) Information extraction by an abstractive text summarization for an Indian regional language. In: Natural language processing and knowledge engineering (NLP-KE), 2011 7th international conference on IEEE, pp 319â€“322
0073 Kedzie et-al. 2015 Kedzie C, McKeown K, Diaz F (2015) Predicting salient updates for disaster summarization. In: Proceedings of the 53rd annual meeting of the ACL and the 7th international conference on natural language processing. pp 1608â€“1617
0001 Khan et-al. 2015 Khan A, Salim N, Jaya Kumar Y (2015) A framework for multi-document abstractive summarization based on semantic role labelling. Appl Soft Comput 30:737â€“747. doi:
0016 Kim and Hovy 2005 Kim SM, Hovy E (2005) Automatic detection of opinion bearing words and sentences. In: Companion volume to the proceedings of the international joint conference on natural language processing (IJCNLP), pp 61â€“66
0056 Ko and Seo 2004 Ko Y, Seo J (2004) Learning with unlabeled data for text categorization using a bootstrapping and a feature projection technique. In: Proceedings of the 42nd annual meeting of the association for computational linguistics (ACL 2004). pp 255â€“262
0103 Ko et-al. 2003 Ko Y, Kim K, Seo J (2003) Topic keyword identification for text summarization using lexical clustering. IEICE Trans Inf Syst E86-D:1695â€“1701
0027 Kulesza and Taskar 2012 Kulesza A, Taskar B (2012) Determinantal point processes for machine learning. arXiv preprint 
0047 Kulkarni and Prasad 2010 Kulkarni UV, Prasad RS (2010) Implementation and evaluation of evolutionary connectionist approaches to automated text summarization. J Comput Sci 6:1366â€“1376
0055 Lee and Seung 1999 Lee DD, Seung HS (1999) Learning the parts of objects by non-negative matrix factorization. Nature 401(6755):788â€“791
0082 Leite and Rino 2006 Leite DS, Rino LHM (2006) Selecting a feature set to summarize texts in Brazilian Portuguese. Advances in artificial intelligence-IBERAMIA-SBIA 2006:462â€“471
0036 Li et-al. 2007 Li JW, Ng KW, Liu Y, Ong KL (2007) Enhancing the effectiveness of clustering with spectra analysis. IEEE Trans Knowl Data Eng 19:887â€“902
0033 Li et-al. 2013 Li C, Liu F, Weng F, Liu Y (2013) Document summarization via guided sentence compression. In: EMNLP, pp 490â€“500
0106 Li et-al. 2015a Li C, Liu Y, Zhao L (2015a) Using external resources and joint learning for bigram weighting in ilp-based multi-document summarization. In: Proceedings of NAACL-HLT, pp 778â€“787
0078 CR92 Li P, Bing L, Lam W, Li H, Liao Y (2015b) Reader-aware multi-document summarization via sparse coding. arXiv preprint 
0080 Lin 2004 Lin CY (2004) ROUGE: a package for automatic evaluation of summaries. In: Proceedings of ACL text summarization workshop, pp 74â€“81
0066 Lin and Bilmes 2010 Lin H, Bilmes J (2010) Multi-document summarization via budgeted maximization of submodular functions. In: Human language technologies: the 2010 annual conference of the North American chapter of the association for computational linguistics, Association for Computational Linguistics, pp 912â€“920
0010 Liu et-al. 2009 Liu X, Webster JJ, Kit C (2009) An extractive text summarizer based on significant words. In: Proceedings of the 22nd international conference on computer processing of oriental languages, language technology for the knowledge-based economy, Springer, pp 168â€“178
0063 Liu et-al. 2015 Liu H, Yu H, Deng ZH (2015) Multi-document summarization based on two-level sparse representation model. In: Twenty-ninth AAAI conference on artificial intelligence
0011 CR100 Lloret E, Palomar M (2011a) Analyzing the use of word graphs for abstractive text summarization. In: IMMM 2011, first international conference, pp 61â€“66
0100 Luhn 1958 Luhn H (1958) The automatic creation of literature abstracts. IBM J Res Dev 2:159â€“165
0009 Mani and Maybury 1999 Mani I, Maybury M (1999) Advances in automatic text summarization. MIT Press, Cambridge
0097 Mihalcea and Tarau 2004 Mihalcea R, Tarau P (2004) TextRank: bringing order into texts. In: Conference on empirical methods in natural language processing. pp 404â€“411
0083 Moawad IF, Aref M 2012 Moawad IF, Aref M (2012) Semantic graph reduction approach for abstractive Text Summarization. In: Proceedings of ICCES 2012, 2012 International Conference on Computer Engineering and Systems, pp 132â€“138. doi:
0013 Murdock 2006 Murdock VG (2006) Aspects of sentence retrieval. University of Massachusetts, Amherst
0029 Neto et-al. 2000 Neto JL, Santos AD, Kaestner CAA, Freitas AA (2000) Document clustering and text summarization. In: Proceedings of the fourth international conference practical applications of knowledge discovery and data mining (padd-2000), pp 41â€“55
0085 Nobata et-al. 2001 Nobata C, Satoshi S, Murata M, Uchimoto K, Utimaya M, Isahara H (2001) Sentence extraction system asssembling multiple evidence. In: Proceedings 2nd NTCIR workshop, pp 319â€“324
0019 Otterbacher et-al. 2009 Otterbacher J, Erkan G, Radev DR (2009) Biased LexRank: passage retrieval using random walks with question-based priors. Inf Process Manag 45(1):42â€“54
0012 Ouyang et-al. 2011 Ouyang Y, Li W, Li S, Lu Q (2011) Applying regression models to query-focused multi-document summarization. Inf Process Manag 47:227â€“237
0025 Owczarzak K 2009 Owczarzak K (2009) DEPEVAL summ: dependency-based evaluation for automatic summaries. In: Proceedings of the joint conference of the 47th annual meeting of the ACL and the 4th international joint conference on natural language processing of the AFNLP. pp 190â€“198
0071 Pang and Lee 2008 Pang B, Lee L (2008) Opinion mining and sentiment analysis. Found Trends Inf Retr 2:1â€“135
0043 Pardo et-al. 2003b Pardo TAS, Rino LHM, Nunes MGV (2003b) Gistsumm: a summarization tool based on a new extractive method. In: Proceedings of the sixth workshop on computational processing of written and spoken portuguese (propor), 2721 of LNAI, pp 210â€“218
0051 Parveen and Strube 2015 Parveen D, Strube M (2015) Integrating importance, non-redundancy and coherence in graph-based extractive summarization. In: Proceedings of the 24th international conference on artificial intelligence. AAAI Press. pp 1298â€“1304
0002 Patel et-al. 2007 Patel A, Siddiqui T, Tiwary US (2007) A language independent approach to multilingual text summarization. In: Large scale semantic access to content (text, image, video, and sound), pp 123â€“132
0109 Radev et-al. 2001 Radev DR, Fan W, Zhang Z, Arbor A (2001) WebInEssence: a personalized web-based multi-document summarization and recommendation system. In: NAACL 2001 workshop on automatic summarization, pp 79â€“88
0059 Radev et-al. 2004a Radev D, Allison T, Goldensohn B et al. (2004a) MEAD: a platform for multidocument multilingual text summarization. Proc Lr, 1â€“4
0023 CR132 Radev DR, Jing HY, Stys M, Tam D (2004b) Centroid-based summarization of multiple documents. Inf Process Manag 40:919â€“938
0057 Riedhammer et-al. 2010 Riedhammer K, Favre B, Hakkani-Tur D (2010) Long story short- global unsupervised models for keyphrase based meeting summarization. Speech Commun 52:801â€“815
0093 Rino and Modolo 2004 Rino LHM, Modolo M (2004) Supor: an environment for as of texts in brazilianportuguese. In: Espana for natural language processsing (EsTAL). pp 419â€“430
0004 Rush et-al. 2015 Rush AM, Chopra S, Weston J (2015) A neural attention model for abstractive sentence summarization. arXiv preprint 
0026 Sanderson M, Croft WB 1999 Sanderson M, Croft WB (1999) Deriving concept hierarchies from text. Proceedings of SIGIR 1999:206â€“213
0094 Sarkar 2010 Sarkar K (2010) Syntactic trimming of extracted sentences for improving extractive multi-document summarization. J Comput 2:177â€“184
0050 Shen et-al. 2011 Shen C, Li T, Ding CH (2011) Integrating clustering and multi-document summarization by bi-mixture probabilistic latent semantic analysis PLSA with sentence bases. In: AAAI
0032 Shen et-al. 2007 Shen D, Sun J-T, Li H et al. (2007) Document summarization using conditional random fields. In: Proceedings of 20th international joint conference on artificial intelligence. pp 2862â€“2867
0081 Simon et-al. 2007 Simon I, Snavely N, Seitz SM (2007) Scene summarization for online image collections. In: Computer vision, 2007. ICCV 2007. IEEE 11th international conference on. IEEE. pp 1â€“8
0053 Sipos et-al. 2012 Sipos R, Shivaswamy P, Joachims T (2012) Large-margin learning of submodular summarization models. In: Proceedings of the 13th conference of the European chapter of the association for computational linguistics, Association for Computational Linguistics, pp 224â€“233
0041 Song et-al. 2011 Song W, Choi LC, Park SC, Ding XF (2011) Fuzzy evolutionary optimization modeling and its applications to unsupervised categorization and extractive summarization. Expert Syst Appl 38:9112â€“9121
0028 Storn R, Price K 1997 Storn R, Price K (1997) Differential evolution-a simple and efficient heuristic for global optimization over continuous spaces. J Glob Optim 11(4):341â€“359
0110 Wang and Li 2012 Wang D, Li T (2012) Weighted consensus multi-document summarization. Inf Process Manag 48:513â€“523
0046 Yang et-al. 2013 Yang C, Shen J, Peng J, Fan J (2013) Image collection summarization via dictionary learning for sparse representation. Pattern Recognit 46(3):948â€“961
0034 Yang et-al. 2014 Yang L, Cai X, Zhang Y, Shi P (2014) Enhancing sentence-level clustering with ranking-based clustering framework for theme-based summarization. Inf Sci 260:37â€“50. doi:
0030 Ye et-al. 2007 Ye S, Chua TS, Kan MY, Qiu L (2007) Document concept lattice for text understanding and summarization. Inf Process Manag 43:1643â€“1662. doi:
0096 Yeh et-al. 2005 Yeh J-Y, Ke H-R, Yang W-P, Meng I-H (2005) Text summarization using a trainable summarizer and latent semantic analysis. Inf Process Manag 41:75â€“95. doi:
0086 Zajic et-al. 2008 Zajic DM, Dorr BJ, Lin J (2008) Single-document and multi-document summarization techniques for e-mail threads using sentence compression. Inf Process Manag 44:1600â€“1610
0107 Zhao et-al. 2009 Zhao L, Wu L, Huang X (2009) Using query expansion in graph-based approach for query-focused multi-document summarization. Inf Process Manag 45(1):35â€“41
